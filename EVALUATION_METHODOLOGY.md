# 評価手法とデータセット準備

## 概要

本研究では、gRPC Protocol Buffersの変更に対する自動修正システムの評価を行う。評価は多段階のフィルタリングプロセスを経て準備されたデータセットを使用し、システムの成功・失敗判定には明確な基準を設定している。

## 1. データセット準備プロセス

### 1.1 初期データセット

- **ソースファイル**: `/app/dataset/P.U_merged_filtered - Final_merged_only_not_excluded_yes_ms_unarchived_commit_hash v2.0.csv`
- **内容**: GitHub上の多様なプロジェクトのIssue/Pull Requestメタデータ
- **対象**: マイクロサービス、アーカイブされていない、コミットハッシュ付きプロジェクト

### 1.2 第1段階フィルタリング: gRPCプロジェクト抽出

#### 抽出条件
- gRPCライブラリを使用するプロジェクトの特定
- Protocol Buffers (`.proto`) ファイルを含むプロジェクト
- 活発に開発されているプロジェクト

#### 出力
- gRPCを利用するプロジェクトのリスト
- 各プロジェクトのIssue/Pull Requestメタデータ

### 1.3 第2段階フィルタリング: .protoファイル変更検出

#### 検出条件
```javascript
const filter = [".proto"];
```

#### 処理内容
- Issue/Pull Requestでのファイル変更を解析
- `.proto`ファイルに変更があるケースのみを抽出
- premerge（変更前）とmerge（変更後）の状態を保存

#### ディレクトリ構造
```
dataset/filtered_commit/
├── {repository_name}/
│   ├── pullrequest/ or issue/
│   │   └── {title}/
│   │       ├── premerge_{hash}/     # 変更前の状態
│   │       └── merge_{hash}/        # 変更後の状態
```

### 1.4 第3段階フィルタリング: 微細変更データセット (`dataset_few_changed.js`)

#### 目的
自動修正に適した「小規模で論理的な変更」のみを抽出し、APR（Automated Program Repair）実験の品質を向上させる。

#### フィルタリング条件

##### 数値基準
```javascript
const ignoredChangedFileNum = 7;     // ファイル変更数上限
const ignoredChangedNum = 30;        // 1ファイルあたり行変更数上限
const countDeletedFiles = false;     // 削除ファイルのカウント除外
```

##### 除外対象ファイル

**1. 自動生成ファイル**
- Protocol Buffers: `.pb.go`, `.pb.cc`, `.pb.h`, `_grpc.pb.go`
- その他: `/generated/`, `/_generated./`, `/mock_.*\.go$/`

**2. 依存関係・設定ファイル**
- `go.mod`, `go.sum`, `package.json`, `package-lock.json`
- `pom.xml`, `build.gradle`, `requirements.txt`

**3. ドキュメント・メタデータ**
- `.md`, `.txt`, `.yml`, `.yaml`, `.json`, `.xml`
- `LICENSE`, `README`, `AUTHORS`

**4. 開発環境・CI/CD**
- `vendor/`, `node_modules/`, `.git/`, `.github/`
- `.vscode/`, `.idea/`, `.DS_Store`
- `.gitlab-ci.yml`, `Jenkinsfile`, `.circleci/`

**5. メディア・バイナリ**
- 画像: `.png`, `.jpg`, `.svg`
- フォント: `.woff`, `.woff2`, `.ttf`
- ドキュメント: `.pdf`, `.mp4`

**6. テストデータ**
- `testdata/`, `fixtures/`, `test/fixtures/`

#### 判定ロジック
```
1. 追加ファイル数 + 削除ファイル数 ≤ 7
2. 各変更ファイルの行変更数 ≤ 30
3. 除外対象でないファイルのみを対象とする
4. バイナリファイルや読み取りエラーは即座に除外
```

#### 出力データセット
- **格納先**: `/app/dataset/filtered_fewChanged/`
- **内容**: 微細な論理的変更のみを含むケース
- **品質**: 手動修正と類似した変更パターン

## 2. システム実行とスクリプト分岐

### 2.1 データセット選択機能

#### 利用可能データセット
| インデックス | データセット名 | 説明 | 用途 |
|:--:|:--|:--|:--|
| 0 | filtered_fewChanged | 少数変更ファイル | デフォルト・主評価用 |
| 1 | filtered_confirmed | 確認済みデータ | 検証済みケース |
| 2 | filtered_commit | コミット履歴データ | 多様性重視評価 |
| 3 | filtered_protoChanged | プロトコル変更データ | .proto特化評価 |
| 4 | test | テスト用データ | 機能検証・デバッグ |

#### 実行パラメータ
| パラメータ | 説明 | デフォルト値 | 例 |
|:--|:--|:--|:--|
| データセットインデックス | 使用するデータセット | 0 (filtered_fewChanged) | 0, 2, 4 |
| 出力ディレクトリ | 結果保存先 | /app/output | /custom/output |

### 2.2 処理オプション設定

#### システム設定
| 設定項目 | 値 | 説明 | 目的 |
|:--|:--|:--|:--|
| 最大リトライ回数 | 3回 | API失敗時の再試行回数 | 一時的障害の回復 |
| タイムアウト時間 | 5分 (300秒) | 1件あたりの処理制限時間 | 無限ループ防止 |
| メモリクリーンアップ間隔 | 5件毎 | ガベージコレクション実行間隔 | メモリ効率化 |
| ガベージコレクション | 有効 | 自動メモリ管理 | システム安定性 |

## 3. APRシステム成功・失敗判定基準

### 3.1 成功判定条件

#### 必須条件（AND条件）
1. **LLM応答の完了タグ存在**
   ```
   応答内に `%%_Fin_%%` タグが含まれている
   ```

2. **応答の構造的正当性**
   ```
   - 有効なJSON形式でパース可能
   - 必要なフィールドが存在
   - 応答長が最小閾値（100文字）以上
   ```

3. **修正内容の存在**
   ```
   - `modified_diff` フィールドが null でない
   - 実際のコード修正が含まれている
   - 最低1行以上の変更が存在
   ```

4. **処理時間内完了**
   ```
   - API応答が5分以内に完了
   - システムタイムアウトに達していない
   ```

#### 品質評価基準
| 評価項目 | 必須/推奨 | 説明 | 判定基準 |
|:--|:--:|:--|:--|
| %%_Fin_%%タグ存在 | 必須 | LLM応答の完了マーカー | タグが応答に含まれる |
| JSON構造正当性 | 必須 | 応答の構造的妥当性 | パース可能なJSON形式 |
| 修正内容存在 | 必須 | 実際のコード修正 | modified_diffフィールドが非null |
| 応答長最小値 | 推奨 | 十分な応答内容 | 100文字以上 |
| 構文有効性 | 推奨 | 生成コードの妥当性 | 構文エラーなし |
| コンテキスト関連度 | 推奨 | 問題への適切な対応 | 変更要求との一致 |

### 3.2 失敗判定条件

#### 即座に失敗とする条件
1. **API通信エラー**
   - ネットワーク接続失敗
   - APIキー認証エラー
   - レート制限超過

2. **応答構造エラー**
   - `%%_Fin_%%` タグが存在しない
   - JSON構造が不正
   - 必須フィールドが欠損

3. **コンテンツエラー**
   - 修正内容が空またはnull
   - 構文エラーを含む応答
   - 無関係な内容の応答

4. **システムエラー**
   - タイムアウト超過
   - メモリ不足
   - ファイルアクセスエラー

### 3.3 リトライ処理

#### リトライ対象エラー
| エラータイプ | エラーコード | 説明 | 優先度 |
|:--|:--|:--|:--:|
| 接続リセット | ECONNRESET | ネットワーク接続の突然切断 | 高 |
| DNS解決失敗 | ENOTFOUND | ドメイン名解決エラー | 高 |
| タイムアウト | ETIMEDOUT | 応答時間超過 | 高 |
| 接続拒否 | ECONNREFUSED | サーバー接続拒否 | 中 |
| レート制限 | RATE_LIMIT | API呼び出し制限 | 高 |
| サービス利用不可 | SERVICE_UNAVAILABLE | 一時的サービス停止 | 中 |

#### リトライロジック
| 段階 | 実行タイミング | 待機時間 | 備考 |
|:--:|:--|:--:|:--|
| 1 | 初回実行 | - | 即座実行 |
| 2 | 1回目リトライ | 1秒 | エラー種別確認後 |
| 3 | 2回目リトライ | 2秒 | 指数バックオフ |
| 4 | 3回目リトライ | 4秒 | 最終試行 |
| 5 | 失敗確定 | - | ログ記録・次項目へ |

#### リトライ除外条件
- 構造的エラー（JSON不正、必須タグ欠損）
- 認証エラー
- 構文エラーを含む応答
- システムリソース不足

### 3.4 スキップ処理

#### スキップ条件
1. **データ不整合**
   ```
   - premergeディレクトリが存在しない
   - mergeまたはcommit_snapshotディレクトリが存在しない
   - 必要なファイルにアクセスできない
   ```

2. **プロンプト生成失敗**
   ```
   - 変数ファイル（01_proto.txt～05_suspectedFiles.txt）生成エラー
   - ディレクトリ構造解析失敗
   - ファイル内容読み取り失敗
   ```

## 4. 評価指標

### 4.1 基本統計
| 指標項目 | 単位 | 説明 | 重要度 |
|:--|:--:|:--|:--:|
| 総処理数 | 件 | 実行対象となったプルリクエスト数 | 必須 |
| 成功数 | 件 | 成功判定されたプルリクエスト数 | 必須 |
| 失敗数 | 件 | 失敗判定されたプルリクエスト数 | 必須 |
| スキップ数 | 件 | 除外条件により処理されなかった数 | 参考 |
| 成功率 | % | (成功数 / 総処理数) × 100 | 主要 |
| 総処理時間 | 秒 | 全体の実行にかかった時間 | 参考 |

### 4.2 品質指標
| 指標項目 | 単位 | 計算方法 | 重要度 |
|:--|:--:|:--|:--:|
| %%_Fin_%%タグ遵守率 | % | タグ含有応答数 / 総応答数 | 必須 |
| 有効JSON率 | % | 解析可能応答数 / 総応答数 | 必須 |
| 修正内容含有率 | % | 修正あり応答数 / 総応答数 | 主要 |
| 平均応答時間 | 秒 | 総応答時間 / 応答数 | 参考 |
| リトライ成功率 | % | リトライ成功数 / リトライ実行数 | 参考 |

### 4.3 エラー分析
```javascript
const errorAnalysis = {
    totalErrors: Number,
    errorsByType: {
        diff_application: Number,    // diff適用エラー
        response_parsing: Number,    // 応答解析エラー
        file_operation: Number       // ファイル操作エラー
    },
    recoveryRate: Percentage        // エラー回復率
};
```

## 5. 実験設定

### 5.1 実行環境
| 設定項目 | 設定値 | 説明 | 備考 |
|:--|:--|:--|:--|
| JavaScript実行環境 | Node.js | ESMモジュール形式 | ES6+対応 |
| アーキテクチャ | MVC | Model-View-Controller | コード分離 |
| 並行処理 | 順次実行 | 同期的プロセス | 安定性重視 |
| メモリ管理 | 定期GC | ガベージコレクション | リソース最適化 |

### 5.2 LLM設定
| パラメータ | 設定値 | 説明 | 理由 |
|:--|:--|:--|:--|
| プロバイダー | OpenAI / Gemini | API選択可能 | 比較検証対応 |
| モデル | gpt-4 | デフォルトモデル | 高性能基準 |
| 創造性 | 0.7 | temperature値 | バランス重視 |
| 最大トークン数 | 4000 | 応答長制限 | 品質・コスト調整 |
| タイムアウト | 5分 | 応答待機時間 | 現実的制限 |

### 5.3 ログ・レポート出力
- **処理統計**: `/app/output/processing_summary_*.json`
- **エラーログ**: `/app/logs/{diff_errors,parsing_errors,file_errors}/`
- **詳細レポート**: 各Pull Request毎の処理結果

## 6. 結果の解釈

### 6.1 成功率の意味
- **高成功率（>80%）**: システムが多様な変更パターンに対応可能
- **中成功率（60-80%）**: 特定パターンで有効、改善余地あり
- **低成功率（<60%）**: システム設計または設定の見直しが必要

### 6.2 エラー分析の活用
- **diff_application**: コード適用ロジックの改善が必要
- **response_parsing**: プロンプト設計またはLLM設定の調整が必要
- **file_operation**: データセット品質またはシステム安定性の改善が必要

### 6.3 データセット品質の影響
- **filtered_fewChanged**: 高品質・小規模変更で高い成功率を期待
- **filtered_commit**: 多様性重視で実世界の変更パターンを反映
- **test**: 制御された環境での機能検証用
