/**
 * å˜ä¸€PRã‚¹ã‚¯ãƒªãƒ—ãƒˆ - æŒ‡å®šã—ãŸ1ã¤ã®PRã®ã¿ã‚’å®Ÿè¡Œ
 * 
 * è²¬ä»»:
 * - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸPRæƒ…å ±ã§å˜ä¸€PRå‡¦ç†ã‚’å®Ÿè¡Œ
 * - ç’°å¢ƒè¨­å®šã¨ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã®åˆæœŸåŒ–
 * - çµæžœã®è¡¨ç¤º
 */

import path from 'path';
import { config } from 'dotenv';
import { fileURLToPath } from 'url';

// ES moduleç’°å¢ƒã§ã® __dirname ã®å–å¾—
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
config({ path: path.join(__dirname, '..', '.env') });

/**
 * ============================================
 * ã“ã“ã§PRæƒ…å ±ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŒ‡å®š
 * ============================================
 */
const TARGET_PR_CONFIG = {
    // ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    // æ³¨æ„: å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æŒ‡å®šã—ã¦ãã ã•ã„
    datasetDir: "/app/dataset/filtered_fewChanged",
    
    // PRæƒ…å ±ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã«åˆã‚ã›ã¦æŒ‡å®šï¼‰
    // ä¾‹: /app/dataset/filtered_fewChanged/repository_name/category_name/pr_title/
    // ä»¥ä¸‹ã¯ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¦ãã ã•ã„
    repositoryName: "boulder",           // ãƒªãƒã‚¸ãƒˆãƒªåï¼ˆä¾‹: "etcd-io_etcd"ï¼‰
    category: "pullrequest",             // ã‚«ãƒ†ã‚´ãƒªåï¼ˆä¾‹: "breaking_changes"ï¼‰
    pullRequestTitle: "Add_certificateProfileName_to_RA-_SA-_and_Core_order_protos",           // PRã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¾‹: "Pull_13207"ï¼‰
    
    // å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    outputDir: "/app/output/single_pr"
};

/**
 * å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
 */
const PROCESSING_OPTIONS = {
    baseOutputDir: TARGET_PR_CONFIG.outputDir,
    maxRetries: 3,
    memoryCleanupInterval: 5,
    timeoutMs: 15 * 60 * 1000,      // 15åˆ†
    enableGarbageCollection: true,
    enablePreVerification: false,
    forceTUI: true,  // TUIé€²æ—è¡¨ç¤ºã‚’å¼·åˆ¶æœ‰åŠ¹åŒ–
    quietMode: false, // è©³ç´°ãƒ­ã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèªç”¨ï¼‰
    
    // å˜ä¸€PRå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    targetPullRequest: {
        repositoryName: TARGET_PR_CONFIG.repositoryName,
        category: TARGET_PR_CONFIG.category,
        pullRequestTitle: TARGET_PR_CONFIG.pullRequestTitle
    }
};

/**
 * ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
 */
async function main() {
    // Configã‚¯ãƒ©ã‚¹ã‚’èª­ã¿è¾¼ã‚“ã§è¨­å®šã‚’å–å¾—
    const configModule = await import('../dist/js/modules/config.js');
    const Config = configModule.default;
    const dummyPRPath = '/app/dataset'; // ãƒ€ãƒŸãƒ¼ãƒ‘ã‚¹ï¼ˆConfigã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆã«å¿…è¦ï¼‰
    const configInstance = new Config(dummyPRPath);
    
    // å®Ÿè¡Œæƒ…å ±ã®è¡¨ç¤º
    console.log('ðŸŽ¯ Single PR Processing Mode');
    console.log('========================================');
    console.log(`ðŸ“‚ Dataset Directory: ${TARGET_PR_CONFIG.datasetDir}`);
    console.log(`ðŸ·ï¸  Repository: ${TARGET_PR_CONFIG.repositoryName}`);
    console.log(`ðŸ“ Category: ${TARGET_PR_CONFIG.category}`);
    console.log(`ðŸ“‹ Pull Request: ${TARGET_PR_CONFIG.pullRequestTitle}`);
    console.log(`ðŸ“ Output Directory: ${TARGET_PR_CONFIG.outputDir}`);
    console.log(`ðŸ› Process ID: ${process.pid}`);
    console.log(`ðŸ“ Node.js Version: ${process.version}`);
    console.log(`ðŸ—‘ï¸ Garbage Collection: ${global.gc ? 'Available' : 'Not Available (use --expose-gc)'}`);
    
    // LLMè¨­å®šæƒ…å ±ã®è¡¨ç¤ºï¼ˆConfigã‚¯ãƒ©ã‚¹ã‹ã‚‰å–å¾—ï¼‰
    const provider = configInstance.get('llm.provider', 'openai');
    console.log('\nðŸ¤– LLM Configuration:');
    console.log(`   Provider: ${provider}`);
    console.log(`   Model: ${getLLMModelFromConfig(configInstance, provider)}`);
    console.log(`   Temperature: ${getLLMTemperatureFromConfig(configInstance, provider)}`);
    console.log(`   Max Tokens: ${getLLMMaxTokensFromConfig(configInstance, provider)}`);
    
    // API Keyæƒ…å ±ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
    console.log(`   API Key Length: ${getLLMApiKeyLength()}`);
    
    // REST APIè¨­å®šã®è¡¨ç¤ºï¼ˆproviderãŒrestapiã®å ´åˆï¼‰
    if (provider === 'restapi') {
        const baseUrl = configInstance.get('llm.restApi.baseUrl', 'http://localhost:1234');
        const endpoint = configInstance.get('llm.restApi.endpoint', '/v1/chat/completions');
        const model = configInstance.get('llm.restApi.model', 'default');
        console.log(`   REST API URL: ${baseUrl}${endpoint}`);
        console.log(`   REST API Model: ${model}`);
    }
    
    // å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¡¨ç¤º
    console.log('\nâš™ï¸ Processing Options:');
    console.log(`   Max Retries: ${PROCESSING_OPTIONS.maxRetries}`);
    console.log(`   Memory Cleanup Interval: ${PROCESSING_OPTIONS.memoryCleanupInterval}`);
    console.log(`   Timeout: ${PROCESSING_OPTIONS.timeoutMs / 1000}s`);
    console.log(`   Garbage Collection: ${PROCESSING_OPTIONS.enableGarbageCollection ? 'Enabled' : 'Disabled'}`);
    console.log(`   Pre-Verification: ${PROCESSING_OPTIONS.enablePreVerification ? 'Enabled' : 'Disabled'}`);
    console.log('========================================\n');

    // PRãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèª
    const prPath = path.join(
        TARGET_PR_CONFIG.datasetDir,
        TARGET_PR_CONFIG.repositoryName,
        TARGET_PR_CONFIG.category,
        TARGET_PR_CONFIG.pullRequestTitle
    );
    
    console.log(`ðŸ” Checking PR path: ${prPath}`);
    
    const fs = await import('fs');
    if (!fs.existsSync(prPath)) {
        console.error(`âŒ PR path does not exist: ${prPath}`);
        console.error('\nðŸ’¡ Please check:');
        console.error(`   - Dataset directory exists: ${TARGET_PR_CONFIG.datasetDir}`);
        console.error(`   - Repository name is correct: ${TARGET_PR_CONFIG.repositoryName}`);
        console.error(`   - Category name is correct: ${TARGET_PR_CONFIG.category}`);
        console.error(`   - Pull request title is correct: ${TARGET_PR_CONFIG.pullRequestTitle}`);
        process.exit(1);
    }
    
    console.log('âœ… PR path verified\n');

    try {
        // å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’èª­ã¿è¾¼ã¿
        const { BatchProcessController } = await import('../dist/js/controllers/BatchProcessController.js');
        
        console.log('ðŸš€ Starting single PR processing...\n');
        
        // ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        const controller = new BatchProcessController({
            generateReport: true,
            generateErrorReport: true,
            ...PROCESSING_OPTIONS
        });
        
        // å˜ä¸€PRå‡¦ç†ã®å®Ÿè¡Œ
        await controller.runBatchProcessing(TARGET_PR_CONFIG.datasetDir);

        console.log('\nðŸŽ‰ Single PR processing completed!');
        console.log(`ðŸ“„ Check output files in: ${TARGET_PR_CONFIG.outputDir}`);
        
        // æ­£å¸¸çµ‚äº†
        process.exit(0);

    } catch (error) {
        console.error('\nâŒ Critical error in single PR processing:');
        console.error('========================================');
        console.error(`Error Type: ${error.constructor.name}`);
        console.error(`Error Message: ${error.message}`);
        if (error.stack) {
            console.error(`Stack Trace:\n${error.stack}`);
        }
        console.error('========================================');
        
        process.exit(1);
    }
}

/**
 * LLMãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ï¼ˆConfigã‚¯ãƒ©ã‚¹ã‹ã‚‰ï¼‰
 */
function getLLMModelFromConfig(configInstance, provider) {
    if (provider === 'openai') {
        return configInstance.get('llm.model', process.env.OPENAI_MODEL || 'gpt-4');
    } else if (provider === 'gemini') {
        return configInstance.get('gemini.model', process.env.GEMINI_MODEL || 'gemini-1.5-pro');
    } else if (provider === 'restapi') {
        return configInstance.get('llm.restApi.model', 'default');
    } else {
        return 'unknown';
    }
}

/**
 * LLMæ¸©åº¦è¨­å®šã‚’å–å¾—ï¼ˆConfigã‚¯ãƒ©ã‚¹ã‹ã‚‰ï¼‰
 */
function getLLMTemperatureFromConfig(configInstance, provider) {
    if (provider === 'openai') {
        return configInstance.get('llm.temperature', process.env.OPENAI_TEMPERATURE || '0.7');
    } else if (provider === 'gemini') {
        return configInstance.get('gemini.temperature', process.env.GEMINI_TEMPERATURE || '0.7');
    } else if (provider === 'restapi') {
        return configInstance.get('llm.restApi.temperature', '0.7');
    } else {
        return 'unknown';
    }
}

/**
 * LLMæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—ï¼ˆConfigã‚¯ãƒ©ã‚¹ã‹ã‚‰ï¼‰
 */
function getLLMMaxTokensFromConfig(configInstance, provider) {
    if (provider === 'openai') {
        return configInstance.get('llm.maxTokens', process.env.OPENAI_MAX_TOKENS || '4000');
    } else if (provider === 'gemini') {
        return configInstance.get('gemini.maxTokens', process.env.GEMINI_MAX_TOKENS || '4000');
    } else if (provider === 'restapi') {
        return configInstance.get('llm.restApi.maxTokens', '4000');
    } else {
        return 'unknown';
    }
}

/**
 * LLMãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ»ãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰
 */
function getLLMModel() {
    const provider = process.env.LLM_PROVIDER || 'openai';
    
    if (provider === 'openai') {
        return process.env.OPENAI_MODEL || 'gpt-4';
    } else if (provider === 'gemini') {
        return process.env.GEMINI_MODEL || 'gemini-1.5-pro';
    } else {
        return 'unknown';
    }
}

/**
 * LLMæ¸©åº¦è¨­å®šã‚’å–å¾—
 */
function getLLMTemperature() {
    const provider = process.env.LLM_PROVIDER || 'openai';
    
    if (provider === 'openai') {
        return process.env.OPENAI_TEMPERATURE || '0.7';
    } else if (provider === 'gemini') {
        return process.env.GEMINI_TEMPERATURE || '0.7';
    } else {
        return 'unknown';
    }
}

/**
 * LLMæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—
 */
function getLLMMaxTokens() {
    const provider = process.env.LLM_PROVIDER || 'openai';
    
    if (provider === 'openai') {
        return process.env.OPENAI_MAX_TOKENS || '4000';
    } else if (provider === 'gemini') {
        return process.env.GEMINI_MAX_TOKENS || '4000';
    } else {
        return 'unknown';
    }
}

/**
 * LLM APIã‚­ãƒ¼ã®é•·ã•ã‚’å–å¾—ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚é•·ã•ã®ã¿è¡¨ç¤ºï¼‰
 */
function getLLMApiKeyLength() {
    const provider = process.env.LLM_PROVIDER || 'openai';
    
    if (provider === 'openai') {
        return (process.env.OPENAI_API_KEY || '').length;
    } else if (provider === 'gemini') {
        return (process.env.GEMINI_API_KEY || '').length;
    } else {
        return 0;
    }
}

// ç›´æŽ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®ã¿ãƒ¡ã‚¤ãƒ³é–¢æ•°ã‚’å®Ÿè¡Œ
if (import.meta.url === `file://${process.argv[1]}`) {
    main().catch(error => {
        console.error('ðŸ’¥ Unhandled error in main:', error);
        process.exit(1);
    });
}

export { 
    main, 
    TARGET_PR_CONFIG, 
    PROCESSING_OPTIONS,
    getLLMModelFromConfig,
    getLLMTemperatureFromConfig,
    getLLMMaxTokensFromConfig
};
