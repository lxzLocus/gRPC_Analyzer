import fs from 'fs';
import path from 'path';
import { config } from 'dotenv';
import { runForAllDatasets } from '../src/modules/llmFlowBatchRunner.js';
import LLMFlowController from '../src/modules/llmFlowController.js';
import { fileURLToPath } from 'url';
import { dirname } from 'path';

// ES moduleç’°å¢ƒã§ã® __dirname ã®å–å¾—
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// ç’°å¢ƒå¤‰æ•°ã®è¨­å®š - æ­£ã—ã„ãƒ‘ã‚¹ã§ .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
config({ path: path.join(__dirname, '..', '..', '..', '.env') });

// ã‚¨ãƒ©ãƒ¼å ±å‘Šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
interface ErrorReport {
    timestamp: string;
    repositoryName: string;
    category: string;
    pullRequestTitle: string;
    pullRequestPath: string;
    premergeDir: string;
    errorType: string;
    errorMessage: string;
    stackTrace: string;
    processingPhase: string;
}

// å‡¦ç†çµ±è¨ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
interface ProcessingStats {
    totalRepositories: number;
    totalCategories: number;
    totalPullRequests: number;
    successfulPullRequests: number;
    failedPullRequests: number;
    skippedPullRequests: number;
    startTime: Date;
    endTime?: Date;
    totalDuration?: number;
    errorsByType: Record<string, number>;
}

class SafeBatchRunner {
    private errorReportFile: string;
    private summaryReportFile: string;
    private stats: ProcessingStats;

    constructor(baseOutputDir: string = '/app/output') {
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        this.errorReportFile = path.join(baseOutputDir, `error_report_${timestamp}.json`);
        this.summaryReportFile = path.join(baseOutputDir, `processing_summary_${timestamp}.json`);
        
        // ç’°å¢ƒå¤‰æ•°ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        console.log(`ğŸ” SafeBatchRunner Environment Debug:`);
        console.log(`   LLM_PROVIDER: ${process.env.LLM_PROVIDER || 'undefined'}`);
        console.log(`   GEMINI_API_KEY length: ${(process.env.GEMINI_API_KEY || '').length}`);
        console.log(`   OPENAI_TOKEN length: ${(process.env.OPENAI_TOKEN || '').length}`);
        console.log(`   OPENAI_API_KEY length: ${(process.env.OPENAI_API_KEY || '').length}`);
        
        this.stats = {
            totalRepositories: 0,
            totalCategories: 0,
            totalPullRequests: 0,
            successfulPullRequests: 0,
            failedPullRequests: 0,
            skippedPullRequests: 0,
            startTime: new Date(),
            errorsByType: {}
        };

        // å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        if (!fs.existsSync(baseOutputDir)) {
            fs.mkdirSync(baseOutputDir, { recursive: true });
        }

        console.log(`ğŸ“‹ Error report will be saved to: ${this.errorReportFile}`);
        console.log(`ğŸ“‹ Summary report will be saved to: ${this.summaryReportFile}`);
    }

    /**
     * ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’è¿½è¨˜
     */
    private appendErrorReport(errorReport: ErrorReport): void {
        try {
            let existingErrors: ErrorReport[] = [];
            
            // æ—¢å­˜ã®ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
            if (fs.existsSync(this.errorReportFile)) {
                const content = fs.readFileSync(this.errorReportFile, 'utf-8');
                existingErrors = JSON.parse(content);
            }

            // æ–°ã—ã„ã‚¨ãƒ©ãƒ¼ã‚’è¿½åŠ 
            existingErrors.push(errorReport);

            // ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
            fs.writeFileSync(this.errorReportFile, JSON.stringify(existingErrors, null, 2));
            
            console.log(`âŒ Error recorded: ${errorReport.pullRequestTitle} (${errorReport.errorType})`);
            console.log(`   Error message: ${errorReport.errorMessage}`);
            console.log(`   Total errors so far: ${existingErrors.length}`);
            
        } catch (writeError) {
            console.error(`âŒ Failed to write error report:`, writeError);
        }
    }

    /**
     * å‡¦ç†çµ±è¨ˆã‚’æ›´æ–°
     */
    private updateStats(type: 'success' | 'failure' | 'skip', errorType?: string): void {
        switch (type) {
            case 'success':
                this.stats.successfulPullRequests++;
                break;
            case 'failure':
                this.stats.failedPullRequests++;
                if (errorType) {
                    this.stats.errorsByType[errorType] = (this.stats.errorsByType[errorType] || 0) + 1;
                }
                break;
            case 'skip':
                this.stats.skippedPullRequests++;
                break;
        }
    }

    /**
     * çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜
     */
    private saveSummaryReport(): void {
        try {
            this.stats.endTime = new Date();
            this.stats.totalDuration = this.stats.endTime.getTime() - this.stats.startTime.getTime();

            const summary = {
                ...this.stats,
                totalDurationFormatted: this.formatDuration(this.stats.totalDuration),
                successRate: this.stats.totalPullRequests > 0 
                    ? Math.round((this.stats.successfulPullRequests / this.stats.totalPullRequests) * 100) 
                    : 0,
                errorReportPath: this.errorReportFile,
                topErrorTypes: Object.entries(this.stats.errorsByType)
                    .sort(([,a], [,b]) => b - a)
                    .slice(0, 5)
                    .map(([type, count]) => ({ type, count }))
            };

            fs.writeFileSync(this.summaryReportFile, JSON.stringify(summary, null, 2));
            console.log(`ğŸ“Š Summary report saved to: ${this.summaryReportFile}`);
            
        } catch (error) {
            console.error(`âŒ Failed to save summary report:`, error);
        }
    }

    /**
     * ç¶™ç¶šæ™‚é–“ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
     */
    private formatDuration(milliseconds: number): string {
        const seconds = Math.floor(milliseconds / 1000);
        const minutes = Math.floor(seconds / 60);
        const hours = Math.floor(minutes / 60);
        
        if (hours > 0) {
            return `${hours}h ${minutes % 60}m ${seconds % 60}s`;
        } else if (minutes > 0) {
            return `${minutes}m ${seconds % 60}s`;
        } else {
            return `${seconds}s`;
        }
    }

    /**
     * å‡¦ç†çµæœã‚’è§£æã—ã¦ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æˆåŠŸ/å¤±æ•—ã‚’åˆ¤å®š
     */
    private analyzeProcessingResult(
        repositoryName: string,
        category: string,
        pullRequestTitle: string,
        pullRequestPath: string,
        premergeDir: string
    ): boolean {
        try {
            // ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œç´¢
            const logDir = path.join('/app/log', repositoryName, category, pullRequestTitle);
            
            if (!fs.existsSync(logDir)) {
                console.log(`âš ï¸  Log directory not found: ${logDir}`);
                return false;
            }
            
            // .logãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            const logFiles = fs.readdirSync(logDir).filter(file => file.endsWith('.log'));
            
            if (logFiles.length === 0) {
                console.log(`âš ï¸  No log files found for ${pullRequestTitle}`);
                return false;
            }
            
            // æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
            const latestLogFile = logFiles.sort().pop();
            if (!latestLogFile) return false;
            
            const logFilePath = path.join(logDir, latestLogFile);
            const logContent = fs.readFileSync(logFilePath, 'utf-8');
            const logData = JSON.parse(logContent);
            
            // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèªï¼ˆ%%_Fin_%%ã‚¿ã‚°ãƒ™ãƒ¼ã‚¹ã®å³å¯†ãªåˆ¤å®šï¼‰
            const status = logData.experiment_metadata?.status || 'Unknown';
            
            // %%_Fin_%%ã‚¿ã‚°ã®å­˜åœ¨ç¢ºèª
            const hasFinTag = logContent.includes('%%_Fin_%%') || status.includes('%%_Fin_%%');
            
            // æ˜ç¤ºçš„ãªã‚¨ãƒ©ãƒ¼ã®ç¢ºèª
            const hasErrors = logContent.includes('400 This model\'s maximum context length') ||
                             logContent.includes('JSON parse failed') ||
                             status.includes('Incomplete') ||
                             status.includes('Error') ||
                             status.includes('Failed');
            
            // æˆåŠŸæ¡ä»¶: %%_Fin_%%ã‚¿ã‚°ãŒã‚ã‚Šã€é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒãªã„
            const isSuccess = hasFinTag && !hasErrors;
            
            console.log(`ğŸ“Š Processing result for ${pullRequestTitle}:`);
            console.log(`   Status: ${status}`);
            console.log(`   %%_Fin_%% tag: ${hasFinTag ? 'YES' : 'NO'}`);
            console.log(`   Has errors: ${hasErrors ? 'YES' : 'NO'}`);
            console.log(`   Final result: ${isSuccess ? 'SUCCESS' : 'FAILURE'}`);
            
            return isSuccess;
            
        } catch (error) {
            console.error(`âŒ Error analyzing processing result for ${pullRequestTitle}:`, error);
            return false;
        }
    }

    /**
     * å˜ä¸€ã®PullRequestã‚’å®‰å…¨ã«å‡¦ç†
     */
    private async processSinglePullRequest(
        repositoryName: string,
        category: string,
        pullRequestTitle: string,
        pullRequestPath: string,
        premergeDir: string
    ): Promise<boolean> {
        let controller: any = null;
        const maxRetries = 3;
        let lastError: Error | null = null;

        for (let retry = 0; retry <= maxRetries; retry++) {
            try {
                console.log(`ğŸ”„ Processing (attempt ${retry + 1}/${maxRetries + 1}): ${repositoryName}/${category}/${pullRequestTitle}`);
                
                // LLMFlowControllerã‚’ç›´æ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
                controller = new LLMFlowController(premergeDir);
                
                // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å¼·åŒ–ã—ãŸå‡¦ç†å®Ÿè¡Œ
                await this.runControllerWithEnhancedErrorHandling(controller, repositoryName, category, pullRequestTitle);
                
                // å‡¦ç†çµæœã‚’è§£æã—ã¦å®Ÿéš›ã®æˆåŠŸ/å¤±æ•—ã‚’åˆ¤å®š
                const isActualSuccess = this.analyzeProcessingResult(
                    repositoryName,
                    category,
                    pullRequestTitle,
                    pullRequestPath,
                    premergeDir
                );
                
                if (isActualSuccess) {
                    console.log(`âœ… Successfully processed: ${pullRequestTitle}`);
                    this.updateStats('success');
                    return true;
                } else {
                    console.log(`âš ï¸  Processing completed but status indicates failure: ${pullRequestTitle}`);
                    this.updateStats('failure', 'ProcessingIncomplete');
                    
                    // å‡¦ç†ã¯å®Œäº†ã—ã¦ã„ã‚‹ãŒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒå¤±æ•—ã®å ´åˆã€ãƒªãƒˆãƒ©ã‚¤ã—ãªã„
                    return false;
                }
                
            } catch (error) {
                lastError = error instanceof Error ? error : new Error(String(error));
                console.error(`âŒ Error in attempt ${retry + 1}/${maxRetries + 1} for ${pullRequestTitle}:`, lastError.message);
                
                // ç‰¹å®šã®ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã¯ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡å¤–
                const isRetryableError = this.isRetryableError(lastError);
                
                if (!isRetryableError || retry === maxRetries) {
                    break;
                }
                
                // ãƒªãƒˆãƒ©ã‚¤å‰ã®å¾…æ©Ÿæ™‚é–“ï¼ˆæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼‰
                const waitTime = Math.pow(2, retry) * 1000; // 1ç§’, 2ç§’, 4ç§’
                console.log(`â³ Waiting ${waitTime}ms before retry...`);
                await new Promise(resolve => setTimeout(resolve, waitTime));
                
                // ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if (controller && typeof controller.cleanup === 'function') {
                    try {
                        await controller.cleanup();
                    } catch (cleanupError) {
                        console.warn(`âš ï¸  Controller cleanup failed: ${cleanupError}`);
                    }
                }
                
                // ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
                if ((global as any).gc) {
                    (global as any).gc();
                }
            }
        }

        // å…¨ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆ
        const errorReport: ErrorReport = {
            timestamp: new Date().toISOString(),
            repositoryName,
            category,
            pullRequestTitle,
            pullRequestPath,
            premergeDir,
            errorType: lastError?.constructor.name || 'UnknownError',
            errorMessage: lastError?.message || 'Unknown error after retries',
            stackTrace: lastError?.stack || '',
            processingPhase: 'CONTROLLER_EXECUTION_WITH_RETRIES'
        };

        this.appendErrorReport(errorReport);
        this.updateStats('failure', errorReport.errorType);
        
        return false;
    }

    /**
     * ã‚¨ãƒ©ãƒ¼ãŒãƒªãƒˆãƒ©ã‚¤å¯èƒ½ã‹ã©ã†ã‹ã‚’åˆ¤å®š
     */
    private isRetryableError(error: Error): boolean {
        const retryablePatterns = [
            /network|timeout|connection/i,
            /rate.*limit/i,
            /temporary|temp/i,
            /502|503|504/i,
            /JSON.*parse/i,
            /SyntaxError/i,
            /unexpected/i
        ];

        const nonRetryablePatterns = [
            /401|403|404|413/i,  // èªè¨¼ãƒ»æ¨©é™ãƒ»è¦‹ã¤ã‹ã‚‰ãªã„ãƒ»ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰éå¤§
            /invalid.*request/i,
            /malformed/i,
            /file.*not.*found/i,
            /directory.*not.*found/i
        ];

        // éãƒªãƒˆãƒ©ã‚¤å¯¾è±¡ã®ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        const errorMessage = error.message.toLowerCase();
        for (const pattern of nonRetryablePatterns) {
            if (pattern.test(errorMessage)) {
                console.log(`ğŸš« Non-retryable error detected: ${error.message}`);
                return false;
            }
        }

        // ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡ã®ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        for (const pattern of retryablePatterns) {
            if (pattern.test(errorMessage)) {
                console.log(`ğŸ”„ Retryable error detected: ${error.message}`);
                return true;
            }
        }

        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡å¤–
        console.log(`â“ Unknown error type, not retrying: ${error.message}`);
        return false;
    }

    /**
     * å¼·åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã§ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’å®Ÿè¡Œ
     */
    private async runControllerWithEnhancedErrorHandling(
        controller: any,
        repositoryName: string,
        category: string,
        pullRequestTitle: string
    ): Promise<void> {
        try {
            // å®Ÿè¡Œå‰ã«ãƒ¡ãƒ¢ãƒªçŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯
            const memUsage = process.memoryUsage();
            console.log(`ğŸ’¾ Memory before execution: RSS=${Math.round(memUsage.rss / 1024 / 1024)}MB, Heap=${Math.round(memUsage.heapUsed / 1024 / 1024)}MB`);

            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ30åˆ†ï¼‰
            const timeoutMs = 30 * 60 * 1000;
            const timeoutPromise = new Promise((_, reject) => {
                setTimeout(() => reject(new Error(`Process timeout after ${timeoutMs / 1000}s`)), timeoutMs);
            });

            // å®Ÿéš›ã®å‡¦ç†å®Ÿè¡Œ
            await Promise.race([
                controller.run(),
                timeoutPromise
            ]);

            console.log(`âœ… Controller execution completed for ${pullRequestTitle}`);

        } catch (error) {
            console.error(`âŒ Enhanced error handler caught error in ${pullRequestTitle}:`, error);
            
            // JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®è©³ç´°åˆ†æ
            if (error instanceof Error && /JSON.*parse|SyntaxError/.test(error.message)) {
                console.log(`ğŸ” JSON Parse Error Analysis:`);
                console.log(`   Error message: ${error.message}`);
                console.log(`   Stack trace preview: ${error.stack?.substring(0, 300)}...`);
                
                // ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å•é¡Œã®ã‚ã‚‹éƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦åˆ†æ
                await this.analyzeJsonParseError(repositoryName, category, pullRequestTitle, error);
            }

            // ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯å¯¾ç­–
            const memUsageAfter = process.memoryUsage();
            console.log(`ğŸ’¾ Memory after error: RSS=${Math.round(memUsageAfter.rss / 1024 / 1024)}MB, Heap=${Math.round(memUsageAfter.heapUsed / 1024 / 1024)}MB`);

            throw error;
        }
    }

    /**
     * JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®è©³ç´°åˆ†æ
     */
    private async analyzeJsonParseError(
        repositoryName: string,
        category: string,
        pullRequestTitle: string,
        error: Error
    ): Promise<void> {
        try {
            const logDir = path.join('/app/log', repositoryName, category, pullRequestTitle);
            if (!fs.existsSync(logDir)) {
                console.log(`âš ï¸  Log directory not found for JSON error analysis: ${logDir}`);
                return;
            }

            const logFiles = fs.readdirSync(logDir).filter(file => file.endsWith('.log'));
            if (logFiles.length === 0) {
                console.log(`âš ï¸  No log files found for JSON error analysis`);
                return;
            }

            const latestLogFile = logFiles.sort().pop();
            if (!latestLogFile) return;

            const logFilePath = path.join(logDir, latestLogFile);
            const logContent = fs.readFileSync(logFilePath, 'utf-8');

            console.log(`ğŸ” JSON Error Analysis for ${pullRequestTitle}:`);
            console.log(`   Log file: ${logFilePath}`);
            console.log(`   Log size: ${Math.round(logContent.length / 1024)}KB`);

            // LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹éƒ¨åˆ†ã‚’æ¤œç´¢
            const llmResponseMatches = logContent.match(/"llm_response":\s*\{[\s\S]*?"raw_content":\s*"([\s\S]*?)"/g);
            if (llmResponseMatches) {
                console.log(`   Found ${llmResponseMatches.length} LLM responses in log`);
                
                // æœ€å¾Œã®LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
                const lastResponse = llmResponseMatches[llmResponseMatches.length - 1];
                const contentMatch = lastResponse.match(/"raw_content":\s*"([\s\S]*?)"/);
                if (contentMatch) {
                    const content = contentMatch[1];
                    console.log(`   Last LLM response length: ${content.length} chars`);
                    console.log(`   Content preview: ${content.substring(0, 200)}...`);
                    
                    // JSONãƒ‘ãƒ¼ã‚¹ãŒå¤±æ•—ã—ãã†ãªç®‡æ‰€ã‚’ç‰¹å®š
                    const problemPatterns = [
                        /\\"/g,  // ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸå¼•ç”¨ç¬¦
                        /\n/g,   // æ”¹è¡Œæ–‡å­—
                        /\r/g,   // å¾©å¸°æ–‡å­—
                        /\t/g,   // ã‚¿ãƒ–æ–‡å­—
                        /\\n/g,  // ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸæ”¹è¡Œ
                        /\\r/g,  // ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸå¾©å¸°
                        /\\t/g   // ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸã‚¿ãƒ–
                    ];
                    
                    for (const pattern of problemPatterns) {
                        const matches = content.match(pattern);
                        if (matches) {
                            console.log(`   Found ${matches.length} instances of ${pattern.toString()}`);
                        }
                    }
                }
            }

        } catch (analysisError) {
            console.error(`âŒ JSON error analysis failed: ${analysisError}`);
        }
    }

    /**
     * å®‰å…¨ãªãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
     */
    async runSafeDatasetProcessing(datasetDir: string): Promise<void> {
        console.log(`ğŸš€ Starting safe batch processing for: ${datasetDir}`);
        console.log(`ğŸ“… Started at: ${this.stats.startTime.toISOString()}`);
        
        try {
            const datasetDirs = fs.readdirSync(datasetDir).filter(dir => 
                fs.statSync(path.join(datasetDir, dir)).isDirectory()
            );
            
            this.stats.totalRepositories = datasetDirs.length;
            console.log(`ğŸ“Š Found ${this.stats.totalRepositories} repositories to process`);

            for (const repositoryName of datasetDirs) {
                const savedRepositoryPath = path.join(datasetDir, repositoryName);
                let categoryDirs: string[] = [];
                
                try {
                    categoryDirs = fs.readdirSync(savedRepositoryPath).filter(dir => 
                        fs.statSync(path.join(savedRepositoryPath, dir)).isDirectory()
                    );
                } catch (err) {
                    console.error(`âŒ Error reading repository ${repositoryName}:`, (err as Error).message);
                    continue;
                }

                this.stats.totalCategories += categoryDirs.length;
                console.log(`ğŸ“ Repository ${repositoryName}: ${categoryDirs.length} categories`);

                for (const category of categoryDirs) {
                    const categoryPath = path.join(savedRepositoryPath, category);
                    let titleDirs: string[] = [];
                    
                    try {
                        titleDirs = fs.readdirSync(categoryPath).filter(dir => 
                            fs.statSync(path.join(categoryPath, dir)).isDirectory()
                        );
                    } catch (err) {
                        console.error(`âŒ Error reading category ${category}:`, (err as Error).message);
                        continue;
                    }

                    this.stats.totalPullRequests += titleDirs.length;
                    console.log(`ğŸ“‹ Category ${category}: ${titleDirs.length} pull requests`);

                    for (const pullRequestTitle of titleDirs) {
                        const pullRequestPath = path.join(categoryPath, pullRequestTitle);

                        try {
                            // premerge_ã§å§‹ã¾ã‚‹ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
                            const premergeDir = fs.readdirSync(pullRequestPath)
                                .map(dir => path.join(pullRequestPath, dir))
                                .find(filePath => 
                                    fs.statSync(filePath).isDirectory() && 
                                    path.basename(filePath).startsWith('premerge')
                                );

                            if (!premergeDir) {
                                console.warn(`âš ï¸  No premerge directory found in ${pullRequestPath}`);
                                this.updateStats('skip');
                                continue;
                            }

                            // å˜ä¸€ã®PullRequestã‚’å®‰å…¨ã«å‡¦ç†
                            const success = await this.processSinglePullRequest(
                                repositoryName,
                                category,
                                pullRequestTitle,
                                pullRequestPath,
                                premergeDir
                            );

                            // é€²æ—å ±å‘Š
                            if (this.stats.totalPullRequests > 0) {
                                const processed = this.stats.successfulPullRequests + this.stats.failedPullRequests + this.stats.skippedPullRequests;
                                const progress = Math.round((processed / this.stats.totalPullRequests) * 100);
                                console.log(`ğŸ“Š Progress: ${processed}/${this.stats.totalPullRequests} (${progress}%) - Success: ${this.stats.successfulPullRequests}, Failed: ${this.stats.failedPullRequests}, Skipped: ${this.stats.skippedPullRequests}`);
                            }

                            // ãƒ¡ãƒ¢ãƒªç®¡ç†ï¼šå®šæœŸçš„ãªã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
                            if ((this.stats.successfulPullRequests + this.stats.failedPullRequests) % 5 === 0) {
                                console.log(`ğŸ—‘ï¸  Running memory management...`);
                                
                                // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒã‚§ãƒƒã‚¯
                                const memUsage = process.memoryUsage();
                                const memUsageMB = {
                                    rss: Math.round(memUsage.rss / 1024 / 1024),
                                    heapUsed: Math.round(memUsage.heapUsed / 1024 / 1024),
                                    heapTotal: Math.round(memUsage.heapTotal / 1024 / 1024),
                                    external: Math.round(memUsage.external / 1024 / 1024)
                                };
                                
                                console.log(`ğŸ’¾ Current memory usage: RSS=${memUsageMB.rss}MB, Heap=${memUsageMB.heapUsed}/${memUsageMB.heapTotal}MB, External=${memUsageMB.external}MB`);
                                
                                // ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
                                if ((global as any).gc) {
                                    (global as any).gc();
                                    
                                    // GCå¾Œã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒã‚§ãƒƒã‚¯
                                    const memUsageAfterGC = process.memoryUsage();
                                    const memUsageAfterMB = {
                                        rss: Math.round(memUsageAfterGC.rss / 1024 / 1024),
                                        heapUsed: Math.round(memUsageAfterGC.heapUsed / 1024 / 1024)
                                    };
                                    
                                    console.log(`ğŸ—‘ï¸  Memory after GC: RSS=${memUsageAfterMB.rss}MB (Î”${memUsageAfterMB.rss - memUsageMB.rss}), Heap=${memUsageAfterMB.heapUsed}MB (Î”${memUsageAfterMB.heapUsed - memUsageMB.heapUsed})`);
                                    
                                    // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé«˜ã„å ´åˆã®è­¦å‘Š
                                    if (memUsageAfterMB.rss > 4000) { // 4GBä»¥ä¸Š
                                        console.warn(`âš ï¸  High memory usage detected: ${memUsageAfterMB.rss}MB RSS`);
                                    }
                                } else {
                                    console.warn(`âš ï¸  Garbage collection not available. Start Node.js with --expose-gc flag for better memory management.`);
                                }
                            }

                        } catch (dirError) {
                            console.error(`âŒ Error processing pullRequest ${pullRequestTitle}:`, dirError);
                            
                            const errorReport: ErrorReport = {
                                timestamp: new Date().toISOString(),
                                repositoryName,
                                category,
                                pullRequestTitle,
                                pullRequestPath,
                                premergeDir: 'N/A',
                                errorType: dirError instanceof Error ? dirError.constructor.name : 'DirectoryError',
                                errorMessage: dirError instanceof Error ? dirError.message : String(dirError),
                                stackTrace: dirError instanceof Error ? dirError.stack || '' : '',
                                processingPhase: 'DIRECTORY_SCANNING'
                            };

                            this.appendErrorReport(errorReport);
                            this.updateStats('failure', errorReport.errorType);
                        }
                    }
                }
            }

        } catch (error) {
            console.error(`âŒ Fatal error in batch processing:`, error);
            throw error;
        } finally {
            // æœ€çµ‚çµ±è¨ˆã‚’ä¿å­˜
            this.saveSummaryReport();
            this.printFinalReport();
        }
    }

    /**
     * æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
     */
    private printFinalReport(): void {
        console.log(`\nğŸ¯ ===== FINAL PROCESSING REPORT =====`);
        console.log(`ğŸ“Š Total Repositories: ${this.stats.totalRepositories}`);
        console.log(`ğŸ“Š Total Categories: ${this.stats.totalCategories}`);
        console.log(`ğŸ“Š Total Pull Requests: ${this.stats.totalPullRequests}`);
        console.log(`âœ… Successful: ${this.stats.successfulPullRequests}`);
        console.log(`âŒ Failed: ${this.stats.failedPullRequests}`);
        console.log(`â­ï¸  Skipped: ${this.stats.skippedPullRequests}`);
        
        if (this.stats.totalPullRequests > 0) {
            const successRate = Math.round((this.stats.successfulPullRequests / this.stats.totalPullRequests) * 100);
            console.log(`ğŸ“ˆ Success Rate: ${successRate}%`);
        }

        if (this.stats.totalDuration) {
            console.log(`â±ï¸  Total Duration: ${this.formatDuration(this.stats.totalDuration)}`);
        }

        console.log(`ğŸ“„ Error Report: ${this.errorReportFile}`);
        console.log(`ğŸ“„ Summary Report: ${this.summaryReportFile}`);
        console.log(`=====================================`);
    }
}

// ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã®å®Ÿè£…
let isShuttingDown = false;
let currentRunner: SafeBatchRunner | null = null;

const gracefulShutdown = (signal: string) => {
    if (isShuttingDown) return;
    isShuttingDown = true;
    
    console.log(`ğŸ“¡ Received ${signal}. Starting graceful shutdown...`);
    
    // ç¾åœ¨ã®çµ±è¨ˆã‚’ä¿å­˜
    if (currentRunner) {
        console.log('ğŸ’¾ Saving current processing state...');
        try {
            (currentRunner as any).saveSummaryReport();
            console.log('âœ… Processing state saved successfully');
        } catch (saveError) {
            console.error('âŒ Failed to save processing state:', saveError);
        }
    }
    
    // ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    console.log('ğŸ§¹ Cleaning up resources...');
    
    // ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå‡¦ç†ã®ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    if (currentRunner) {
        try {
            // ç¾åœ¨é€²è¡Œä¸­ã®å‡¦ç†ã®æƒ…å ±ã‚’ä¿å­˜
            const currentStats = (currentRunner as any).stats;
            console.log(`ğŸ“Š Final stats before shutdown: Success=${currentStats.successfulPullRequests}, Failed=${currentStats.failedPullRequests}, Skipped=${currentStats.skippedPullRequests}`);
        } catch (statError) {
            console.error('âŒ Error accessing current stats:', statError);
        }
    }
    
    // ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å¼·åˆ¶å®Ÿè¡Œ
    if ((global as any).gc) {
        console.log('ğŸ—‘ï¸ Running final garbage collection...');
        try {
            (global as any).gc();
            console.log('âœ… Garbage collection completed');
        } catch (gcError) {
            console.error('âŒ Garbage collection failed:', gcError);
        }
    }
    
    // ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã®è¡¨ç¤º
    const memUsage = process.memoryUsage();
    console.log(`ğŸ’¾ Final memory usage: RSS=${Math.round(memUsage.rss / 1024 / 1024)}MB, Heap=${Math.round(memUsage.heapUsed / 1024 / 1024)}MB`);
    
    console.log('âœ… Graceful shutdown completed');
    process.exit(0);
};

// ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
process.on('SIGINT', () => gracefulShutdown('SIGINT'));
process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));

// ç•°å¸¸çµ‚äº†ã®ã‚­ãƒ£ãƒƒãƒ
process.on('uncaughtException', (error) => {
    console.error('âŒ Uncaught Exception:', error.message);
    console.error('Stack:', error.stack);
    
    // ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
    if (currentRunner) {
        try {
            const errorReport = {
                timestamp: new Date().toISOString(),
                repositoryName: 'SYSTEM',
                category: 'UNCAUGHT_EXCEPTION',
                pullRequestTitle: 'N/A',
                pullRequestPath: 'N/A',
                premergeDir: 'N/A',
                errorType: error.constructor.name,
                errorMessage: error.message,
                stackTrace: error.stack || '',
                processingPhase: 'SYSTEM_LEVEL'
            };
            
            (currentRunner as any).appendErrorReport(errorReport);
            console.log('ğŸ“ Uncaught exception logged to error report');
        } catch (logError) {
            console.error('âŒ Failed to log uncaught exception:', logError);
        }
    }
    
    gracefulShutdown('uncaughtException');
});

process.on('unhandledRejection', (reason, promise) => {
    console.error('âŒ Unhandled Rejection at:', promise, 'reason:', reason);
    
    // Unhandled rejectionã®è©³ç´°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
    if (currentRunner) {
        try {
            const errorReport = {
                timestamp: new Date().toISOString(),
                repositoryName: 'SYSTEM',
                category: 'UNHANDLED_REJECTION',
                pullRequestTitle: 'N/A',
                pullRequestPath: 'N/A',
                premergeDir: 'N/A',
                errorType: reason instanceof Error ? reason.constructor.name : 'UnhandledRejection',
                errorMessage: reason instanceof Error ? reason.message : String(reason),
                stackTrace: reason instanceof Error ? reason.stack || '' : '',
                processingPhase: 'PROMISE_REJECTION'
            };
            
            (currentRunner as any).appendErrorReport(errorReport);
            console.log('ğŸ“ Unhandled rejection logged to error report');
        } catch (logError) {
            console.error('âŒ Failed to log unhandled rejection:', logError);
        }
    }
    
    gracefulShutdown('unhandledRejection');
});

// ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–ï¼ˆå®šæœŸãƒã‚§ãƒƒã‚¯ï¼‰
setInterval(() => {
    if (!isShuttingDown && currentRunner) {
        const memUsage = process.memoryUsage();
        const memUsageMB = Math.round(memUsage.rss / 1024 / 1024);
        
        // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç•°å¸¸ã«é«˜ã„å ´åˆã®è­¦å‘Š
        if (memUsageMB > 6000) { // 6GBä»¥ä¸Š
            console.warn(`âš ï¸  CRITICAL: Very high memory usage detected: ${memUsageMB}MB`);
            console.warn(`âš ï¸  Consider terminating the process to prevent system instability`);
            
            // ç·Šæ€¥ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            if ((global as any).gc) {
                console.log('ğŸš¨ Running emergency garbage collection...');
                (global as any).gc();
            }
        } else if (memUsageMB > 4000) { // 4GBä»¥ä¸Š
            console.warn(`âš ï¸  High memory usage: ${memUsageMB}MB - monitoring closely`);
        }
    }
}, 60000); // 60ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯

// ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
if (import.meta.url === `file://${process.argv[1]}`) {
    const datasetDir = process.argv[2] || "/app/dataset/filtered_fewChanged";
    const outputDir = process.argv[3] || "/app/output";
    
    console.log(`ğŸ¯ Safe Batch Runner Starting...`);
    console.log(`ğŸ“ Dataset Directory: ${datasetDir}`);
    console.log(`ğŸ“ Output Directory: ${outputDir}`);
    console.log(`ğŸ› Process ID: ${process.pid}`);
    console.log(`ğŸ’¾ Node.js Version: ${process.version}`);
    console.log(`ğŸ—‘ï¸  Garbage Collection: ${(global as any).gc ? 'Available' : 'Not Available (use --expose-gc)'}`);
    
    // ãƒ¡ãƒ¢ãƒªåˆ¶é™ã®ç¢ºèªã¨è¨­å®š
    const memUsage = process.memoryUsage();
    console.log(`ğŸ’¾ Initial Memory: RSS=${Math.round(memUsage.rss / 1024 / 1024)}MB, Heap=${Math.round(memUsage.heapUsed / 1024 / 1024)}MB`);
    
    try {
        // ãƒ—ãƒ­ã‚»ã‚¹åˆ¶é™ã®ç¢ºèª
        if (process.platform === 'linux') {
            console.log(`ğŸ”§ Platform: ${process.platform} (containerized environment)`);
        }
        
        // ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®äº‹å‰ãƒã‚§ãƒƒã‚¯
        if (!fs.existsSync(datasetDir)) {
            throw new Error(`Dataset directory not found: ${datasetDir}`);
        }
        
        // ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        if (!fs.existsSync(outputDir)) {
            fs.mkdirSync(outputDir, { recursive: true });
            console.log(`ğŸ“ Created output directory: ${outputDir}`);
        }
        
        // ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ã®è¨˜éŒ²
        console.log(`â° Process started at: ${new Date().toISOString()}`);
        
        currentRunner = new SafeBatchRunner(outputDir);
        await currentRunner.runSafeDatasetProcessing(datasetDir);
        console.log("âœ… Safe batch processing completed successfully.");
        
        // æ­£å¸¸çµ‚äº†
        process.exit(0);
    } catch (error) {
        console.error("âŒ Critical error in safe batch processing:", error);
        
        // æœ€çµ‚ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        if (currentRunner) {
            try {
                const finalErrorReport = {
                    timestamp: new Date().toISOString(),
                    repositoryName: 'SYSTEM',
                    category: 'CRITICAL_ERROR',
                    pullRequestTitle: 'BATCH_PROCESSING',
                    pullRequestPath: datasetDir,
                    premergeDir: 'N/A',
                    errorType: error instanceof Error ? error.constructor.name : 'CriticalError',
                    errorMessage: error instanceof Error ? error.message : String(error),
                    stackTrace: error instanceof Error ? error.stack || '' : '',
                    processingPhase: 'BATCH_INITIALIZATION'
                };
                
                (currentRunner as any).appendErrorReport(finalErrorReport);
                console.log('ğŸ“ Critical error logged to final error report');
            } catch (reportError) {
                console.error('âŒ Failed to log critical error:', reportError);
            }
        }
        
        gracefulShutdown('error');
    }
}

export { SafeBatchRunner };
