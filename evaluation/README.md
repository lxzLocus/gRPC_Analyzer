# APRè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ  - ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€LLMãƒ™ãƒ¼ã‚¹ã®APR (Automatic Program Repair) ã‚·ã‚¹ãƒ†ãƒ ã®åŒ…æ‹¬çš„ãªè©•ä¾¡æ©Ÿèƒ½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚2æ®µéšè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ã®é©åˆæ€§ã¨ãƒ‘ãƒƒãƒå“è³ªã‚’å®šé‡çš„ãƒ»å®šæ€§çš„ã«è©•ä¾¡ã—ã¾ã™ã€‚

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ç’°å¢ƒç¢ºèª
```bash
cd /app/.docker
./manage.sh eval-setup
```

### 2. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
```bash
./manage.sh eval-dry-run
```

### 3. å°è¦æ¨¡è©•ä¾¡
```bash
./manage.sh eval-run --mode compliance --limit 10
```

### 4. å®Œå…¨è©•ä¾¡
```bash
./manage.sh eval-run --mode full
```

## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
/app/evaluation/                    # è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãƒ«ãƒ¼ãƒˆ
â”œâ”€â”€ main.py                        # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ Dockerfile_evaluation          # Dockerè¨­å®š
â”œâ”€â”€ requirements_evaluation.txt    # Pythonä¾å­˜é–¢ä¿‚
â”œâ”€â”€ ğŸ“‹ HANDOVER_DOCUMENTATION.md   # å¼•ãç¶™ããƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆé‡è¦ï¼‰
â”œâ”€â”€ ğŸ› ï¸ DEVELOPMENT_GUIDE.md        # é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰
â”œâ”€â”€ ğŸ“š API_SPECIFICATION.md        # APIä»•æ§˜æ›¸
â”œâ”€â”€ ğŸ“Š SYSTEM_SPECIFICATION.md     # ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜æ›¸
â”œâ”€â”€ evaluation-design/             # è©•ä¾¡è¨­è¨ˆ
â”‚   â”œâ”€â”€ integrated-evaluation-system.md
â”‚   â”œâ”€â”€ step1-system-compliance-evaluator.md
â”‚   â”œâ”€â”€ step2-patch-quality-evaluator.md
â”‚   â””â”€â”€ prompt-templates/
â”œâ”€â”€ src/                           # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ evaluators/
â”‚   â”œâ”€â”€ analyzers/
â”‚   â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ reporters/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ config/                        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ results/                       # è©•ä¾¡çµæœå‡ºåŠ›
â”œâ”€â”€ logs/                          # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ apr-logs/                      # APRãƒ­ã‚°ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
â”œâ”€â”€ apr-output/                    # APRçµæœï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
â””â”€â”€ dataset/                       # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
```

## âš™ï¸ ä¸»è¦ã‚³ãƒãƒ³ãƒ‰

### manage.sh ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½¿ç”¨

```bash
# ã‚³ãƒ³ãƒ†ãƒŠãƒ“ãƒ«ãƒ‰
./manage.sh build

# è©•ä¾¡å®Ÿè¡Œ
./manage.sh eval-run

# ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆè¨­å®šç¢ºèªï¼‰
./manage.sh eval-dry-run

# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç¢ºèª
./manage.sh eval-setup

# ãƒ‡ãƒ¼ã‚¿ãƒªã‚»ãƒƒãƒˆ
./manage.sh reset

# ãƒ­ã‚°ç¢ºèª
./manage.sh logs evaluation-system
```

### ç›´æ¥å®Ÿè¡Œï¼ˆã‚³ãƒ³ãƒ†ãƒŠå†…ï¼‰

```bash
# ã‚³ãƒ³ãƒ†ãƒŠã«å…¥ã‚‹
docker exec -it grpc-analyzer-evaluation bash

# åŸºæœ¬è©•ä¾¡
python main.py --mode full

# ç‰¹å®šãƒ¢ãƒ¼ãƒ‰
python main.py --mode compliance --project servantes
python main.py --mode quality --dataset filtered_confirmed

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
python main.py --debug --verbose --log-level DEBUG
```

## ğŸ¯ è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰

| ãƒ¢ãƒ¼ãƒ‰ | èª¬æ˜ | å®Ÿè¡Œæ™‚é–“ |
|--------|------|----------|
| `setup` | ç’°å¢ƒç¢ºèªãƒ»åˆæœŸè¨­å®š | 1-2åˆ† |
| `compliance` | ã‚·ã‚¹ãƒ†ãƒ é©åˆæ€§è©•ä¾¡ã®ã¿ | 5-10åˆ† |
| `quality` | ãƒ‘ãƒƒãƒå“è³ªè©•ä¾¡ã®ã¿ | 15-30åˆ† |
| `full` | å®Œå…¨è©•ä¾¡ï¼ˆä¸¡æ®µéšï¼‰ | 20-40åˆ† |
| `dry-run` | è¨­å®šç¢ºèªï¼ˆå®Ÿéš›ã®è©•ä¾¡ãªã—ï¼‰ | 1åˆ† |

## ğŸ“Š å‡ºåŠ›çµæœ

### è©•ä¾¡çµæœ
- **å ´æ‰€**: `/app/results/`
- **å½¢å¼**: JSON, CSV, HTML
- **å†…å®¹**: è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€çµ±è¨ˆã‚µãƒãƒªãƒ¼

### å¯è¦–åŒ–
- **å ´æ‰€**: `/app/results/charts/`
- **å½¢å¼**: PNG, PDF
- **å†…å®¹**: çµ±è¨ˆã‚°ãƒ©ãƒ•ã€æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ

## âš ï¸ é‡è¦ãªè¨­å®š

### ç’°å¢ƒå¤‰æ•°
```bash
PYTHONPATH=/app                    # å¿…é ˆ
EVALUATION_MODE=production         # å¿…é ˆ
OPENAI_API_KEY=your_key_here      # OpenAIä½¿ç”¨æ™‚
ANTHROPIC_API_KEY=your_key_here   # Anthropicä½¿ç”¨æ™‚
```

### ãƒ›ã‚¹ãƒˆãƒ‘ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°
```
F:/Workspace/gRPC_Analyzer/evaluation â†’ /app/
F:/Workspace/gRPC_Analyzer/dataset   â†’ /app/dataset
F:/Workspace/gRPC_Analyzer/log       â†’ /app/apr-logs
F:/Workspace/gRPC_Analyzer/output    â†’ /app/apr-output
```

## ğŸ†˜ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **ãƒ‘ã‚¹é–¢é€£ã‚¨ãƒ©ãƒ¼**
   ```bash
   # è§£æ±ºç­–: docker-compose.ymlã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ç¢ºèª
   ERROR: Required directory not found: /app/apr-logs
   ```

2. **LLM API ã‚¨ãƒ©ãƒ¼**
   ```bash
   # è§£æ±ºç­–: API ã‚­ãƒ¼ç¢ºèªã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®èª¿æ•´
   OpenAI API rate limit exceeded
   ```

3. **ãƒ¡ãƒ¢ãƒªä¸è¶³**
   ```bash
   # è§£æ±ºç­–: ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãè¨­å®š
   MemoryError during batch processing
   ```

### ãƒ­ã‚°ç¢ºèª
```bash
# è©•ä¾¡ãƒ­ã‚°
./manage.sh logs evaluation-system

# ã‚¨ãƒ©ãƒ¼æ¤œç´¢
docker exec grpc-analyzer-evaluation grep -r "ERROR" /app/logs/

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèª
docker exec grpc-analyzer-evaluation ls -la /app/logs/performance/
```

## ğŸ“š è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- **ğŸ¯ æ–°è¦å¼•ãç¶™ã**: `HANDOVER_DOCUMENTATION.md` - **å¿…èª­**
- **ğŸ› ï¸ é–‹ç™ºç¶™ç¶š**: `DEVELOPMENT_GUIDE.md`
- **ğŸ“š APIä½¿ç”¨**: `API_SPECIFICATION.md`
- **ğŸ“Š ä»•æ§˜è©³ç´°**: `SYSTEM_SPECIFICATION.md`
- **ğŸ¨ è©•ä¾¡è¨­è¨ˆ**: `evaluation-design/`

## ğŸš€ å§‹ã‚ã¦ã¿ã‚ˆã†

**æ–°è¦å¼•ãç¶™ãè€…ã®æ–¹ã¸**:

1. **å¿…èª­ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: `HANDOVER_DOCUMENTATION.md`
2. **ç’°å¢ƒç¢ºèª**: `./manage.sh eval-setup`
3. **ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ**: `./manage.sh eval-dry-run`
4. **å°è¦æ¨¡è©•ä¾¡**: `./manage.sh eval-run --mode compliance --limit 5`

**é–‹ç™ºè€…ã®æ–¹ã¸**:

1. **é–‹ç™ºã‚¬ã‚¤ãƒ‰**: `DEVELOPMENT_GUIDE.md`
2. **APIä»•æ§˜**: `API_SPECIFICATION.md`
3. **ãƒ†ã‚¹ãƒˆ**: `python -m pytest src/tests/ -v`

---

**ä½œæˆæ—¥**: 2025-07-22  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0  
**ã‚·ã‚¹ãƒ†ãƒ **: gRPC_Analyzer APRè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
cd /app/.docker
./manage.sh build

# è©•ä¾¡å®Ÿè¡Œ
./manage.sh eval-all

# è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚·ã‚§ãƒ«
./manage.sh shell evaluation-system
```

### è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ å†…ã§ç›´æ¥å®Ÿè¡Œ
```bash
# å…¨è©•ä¾¡å®Ÿè¡Œ
python main.py --step all

# å€‹åˆ¥è©•ä¾¡
python main.py --step 1  # ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜æº–æ‹ æ€§
python main.py --step 2  # ãƒ‘ãƒƒãƒå“è³ª

# ç’°å¢ƒãƒã‚§ãƒƒã‚¯
python main.py --dry-run
```

## ğŸ“Š è©•ä¾¡ãƒ•ãƒ­ãƒ¼

1. **ã‚¹ãƒ†ãƒƒãƒ—1**: ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜æº–æ‹ æ€§è©•ä¾¡
   - APRãƒ­ã‚°ï¼ˆ`/app/apr-logs/`ï¼‰ã‚’åˆ†æ
   - åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã€ãƒ‘ãƒ¼ã‚µãƒ¼ç²¾åº¦ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è©•ä¾¡
   - çµæœ: `/app/results/step1/`

2. **ã‚¹ãƒ†ãƒƒãƒ—2**: ãƒ‘ãƒƒãƒå“è³ªè©•ä¾¡
   - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ`/app/dataset/`ï¼‰ã¨APRçµæœï¼ˆ`/app/apr-output/`ï¼‰ã‚’æ¯”è¼ƒ
   - Plausibilityã€Correctnessã€Reasoning Qualityã‚’è©•ä¾¡
   - çµæœ: `/app/results/step2/`

3. **çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ**: åŒ…æ‹¬çš„ãªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
   - çµæœ: `/app/results/comprehensive_*.json`

## ğŸ”§ è¨­å®š

### ç’°å¢ƒå¤‰æ•°
- `PYTHONPATH=/app`
- `EVALUATION_MODE=production`

### å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
- **APRãƒ­ã‚°**: `/app/apr-logs/` (F:\Workspace\gRPC_Analyzer\log)
- **APRçµæœ**: `/app/apr-output/` (F:\Workspace\gRPC_Analyzer\output)
- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: `/app/dataset/` (F:\Workspace\gRPC_Analyzer\dataset)

### å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿
- **è©•ä¾¡çµæœ**: `/app/results/` (F:\Workspace\gRPC_Analyzer\evaluation\results)

## ğŸ› ï¸ é–‹ç™º

### ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º
```bash
# è©•ä¾¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ä½œæ¥­
cd /app/evaluation

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements_evaluation.txt

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
python main.py --dry-run
```

### æ–°ã—ã„è©•ä¾¡å™¨è¿½åŠ 
1. `step3_*.py` ãªã©ã®æ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ
2. `main.py` ã«çµ±åˆ
3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¿½åŠ 
