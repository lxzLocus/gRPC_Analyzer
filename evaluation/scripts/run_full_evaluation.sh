#!/bin/bash
# å…¨ãƒ­ã‚°è©•ä¾¡å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ã™ã¹ã¦ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ­ã‚°ã«å¯¾ã—ã¦è©•ä¾¡ã‚’å®Ÿè¡Œ

echo "ðŸ”¥ å…¨APRãƒ­ã‚°è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ  - å®Œå…¨å®Ÿè¡Œ"
echo "=================================="

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
if [ -f "/app/.env" ]; then
    echo "ðŸ“„ .envãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ä¸­..."
    export $(grep -v '^#' /app/.env | xargs)
    echo "âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ"
    echo ""
fi

# OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
if [ -z "$OPENAI_API_KEY" ]; then
    echo "âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    echo ""
    echo "ðŸ“‹ MockLLMã§å…¨è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"
    PROVIDER="mock"
    MODEL="mock-gpt"
    echo "ðŸŽ­ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${PROVIDER}, ãƒ¢ãƒ‡ãƒ«: ${MODEL}"
else
    echo "âœ… OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™"
    echo ""
    echo "ðŸ’¡ è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠžã—ã¦ãã ã•ã„:"
    echo "1. Mock LLMï¼ˆãƒ†ã‚¹ãƒˆç”¨ãƒ»é«˜é€Ÿãƒ»ç„¡æ–™ï¼‰"
    echo "2. OpenAI gpt-4.1-miniï¼ˆé«˜å“è³ªãƒ»ä½Žã‚³ã‚¹ãƒˆï¼‰"
    echo "3. OpenAI gpt-4.1ï¼ˆæœ€é«˜å“è³ªãƒ»é«˜ã‚³ã‚¹ãƒˆï¼‰"
    echo ""
    read -p "é¸æŠž (1-3, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:1): " -n 1 -r
    echo
    
    case $REPLY in
        2)
            PROVIDER="openai"
            MODEL="gpt-4.1-mini"
            ;;
        3)
            PROVIDER="openai"
            MODEL="gpt-4.1"
            ;;
        *)
            PROVIDER="mock"
            MODEL="mock-gpt"
            ;;
    esac
    
    echo "ðŸ¤– é¸æŠžã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${PROVIDER}"
    echo "ðŸ§  é¸æŠžã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: ${MODEL}"
fi

echo ""

# åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ã‚’å–å¾—
echo "ðŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµ±è¨ˆæƒ…å ±ã‚’å–å¾—ä¸­..."
cd /app && python3 -c "
import sys
sys.path.append('/app/src')
from utils.log_iterator import APRLogIterator

iterator = APRLogIterator('/app')
stats = iterator.get_statistics()

print(f'ðŸ“ˆ ç·ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {stats[\"total_projects\"]}')
print(f'ðŸ“ˆ ç·ãƒ­ã‚°æ•°: {stats[\"overall\"][\"total_logs\"]}')
print()

print('ðŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥ãƒ­ã‚°æ•°:')
projects = []
for project_name, project_stats in sorted(stats['projects'].items()):
    log_count = project_stats['total_logs']
    print(f'  {project_name:20s}: {log_count:3d}ãƒ­ã‚°')
    projects.append((project_name, log_count))

import json
with open('/tmp/project_stats.json', 'w') as f:
    json.dump(projects, f)
"

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’èª­ã¿è¾¼ã¿
PROJECTS=$(python3 -c "
import json
with open('/tmp/project_stats.json', 'r') as f:
    projects = json.load(f)
print(' '.join([p[0] for p in projects]))
")

echo ""
echo "ðŸš€ å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ"
echo "å¯¾è±¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ${PROJECTS}"
echo "ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${PROVIDER} (${MODEL})"
echo ""
read -p "å®Ÿè¡Œã—ã¾ã™ã‹? (y/N): " -n 1 -r
echo

if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "â¹ï¸ å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ"
    exit 0
fi

# é–‹å§‹æ™‚åˆ»è¨˜éŒ²
START_TIME=$(date +%s)
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

echo ""
echo "ðŸ”¥ å…¨APRãƒ­ã‚°è©•ä¾¡é–‹å§‹ - ${TIMESTAMP}"
echo "======================================"

# ãƒ­ã‚°ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆ
BASE_LOG_DIR="/app/logs"
SESSION_DIR="${BASE_LOG_DIR}/full_evaluation_${TIMESTAMP}"
RESULTS_DIR="${SESSION_DIR}/results"
DETAILED_DIR="${SESSION_DIR}/detailed_responses"
SUMMARY_DIR="${SESSION_DIR}/summaries"

mkdir -p "${RESULTS_DIR}"
mkdir -p "${DETAILED_DIR}"
mkdir -p "${SUMMARY_DIR}"

# çµ±åˆãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
LOG_FILE="${SESSION_DIR}/full_evaluation.log"
exec > >(tee -a "${LOG_FILE}")
exec 2>&1

echo "ðŸ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜å…ˆ: ${SESSION_DIR}"
echo "ðŸ“‹ çµ±åˆãƒ­ã‚°: ${LOG_FILE}"
echo "ðŸ“Š è©•ä¾¡çµæžœ: ${RESULTS_DIR}"
echo "ðŸ” è©³ç´°ãƒ¬ã‚¹ãƒãƒ³ã‚¹: ${DETAILED_DIR}"
echo "ðŸ“ˆ ã‚µãƒžãƒªãƒ¼: ${SUMMARY_DIR}"
echo ""

# å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é †æ¬¡è©•ä¾¡
TOTAL_PROCESSED=0
TOTAL_SUCCESS=0
TOTAL_FAILED=0

for PROJECT in ${PROJECTS}; do
    echo ""
    echo "ðŸ”„ ================================"
    echo "ðŸ”„ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ${PROJECT}"
    echo "ðŸ”„ ================================"
    
    PROJECT_START=$(date +%s)
    
    # è©•ä¾¡å®Ÿè¡Œ
    if cd /app && python scripts/real_llm_evaluator.py --repo "${PROJECT}" --max-logs 999 --provider "${PROVIDER}" --model "${MODEL}"; then
        PROJECT_END=$(date +%s)
        PROJECT_TIME=$((PROJECT_END - PROJECT_START))
        
        echo "âœ… ${PROJECT} è©•ä¾¡å®Œäº† (${PROJECT_TIME}ç§’)"
        ((TOTAL_SUCCESS++))
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆï¼ˆAPRãƒ­ã‚°æ§‹é€ ã«åˆã‚ã›ã‚‹ï¼‰
        PROJECT_RESULTS_DIR="${RESULTS_DIR}/${PROJECT}"
        PROJECT_DETAILED_DIR="${DETAILED_DIR}/${PROJECT}"
        mkdir -p "${PROJECT_RESULTS_DIR}"
        mkdir -p "${PROJECT_DETAILED_DIR}"
        
        # è©•ä¾¡çµæžœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†ã—ã¦ã‚³ãƒ”ãƒ¼
        LATEST_RESULT=$(ls -t /app/verification_results/real_llm_analysis_${PROJECT}_*.json 2>/dev/null | head -1)
        if [ -n "${LATEST_RESULT}" ]; then
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰è©³ç´°æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãƒªãƒãƒ¼ãƒ 
            RESULT_BASENAME=$(basename "${LATEST_RESULT}")
            CLEAN_NAME="${RESULT_BASENAME#real_llm_analysis_${PROJECT}_}"
            cp "${LATEST_RESULT}" "${PROJECT_RESULTS_DIR}/evaluation_result_${CLEAN_NAME}"
            echo "ðŸ“‹ è©•ä¾¡çµæžœä¿å­˜: ${PROJECT_RESULTS_DIR}/evaluation_result_${CLEAN_NAME}"
            
            # å„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å€‹åˆ¥ã«APRæ§‹é€ ã«åˆ†ã‘ã‚‹
            echo "ðŸ” ${PROJECT} ã®å€‹åˆ¥ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ§‹é€ åŒ–..."
            python3 -c "
import json
import os
from pathlib import Path

# è©•ä¾¡çµæžœã‚’èª­ã¿è¾¼ã¿
with open('${LATEST_RESULT}', 'r', encoding='utf-8') as f:
    data = json.load(f)

# è©³ç´°çµæžœã‹ã‚‰å€‹åˆ¥ãƒ­ã‚°æƒ…å ±ã‚’æŠ½å‡º
if 'Mock_LLM' in data:
    detailed_results = data['Mock_LLM'].get('detailed_results', [])
elif 'Real_OPENAI_Analysis' in data:
    detailed_results = data['Real_OPENAI_Analysis'].get('detailed_results', [])
else:
    detailed_results = data.get('detailed_results', [])

for result in detailed_results:
    log_path = result.get('log_path', '')
    if log_path:
        # ãƒ­ã‚°ãƒ‘ã‚¹ã‹ã‚‰ repository/category/pr_name ã‚’æŠ½å‡º
        # ä¾‹: /app/apr-logs/boulder/pullrequest/Add_validated_timestamp_to_challenges/...
        path_parts = Path(log_path).parts
        if len(path_parts) >= 5 and 'apr-logs' in path_parts:
            apr_idx = path_parts.index('apr-logs')
            repo = path_parts[apr_idx + 1] if apr_idx + 1 < len(path_parts) else 'unknown'
            category = path_parts[apr_idx + 2] if apr_idx + 2 < len(path_parts) else 'unknown' 
            pr_name = path_parts[apr_idx + 3] if apr_idx + 3 < len(path_parts) else 'unknown'
            
            if repo == '${PROJECT}':
                # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                category_dir = Path('${PROJECT_RESULTS_DIR}') / category / pr_name
                category_dir.mkdir(parents=True, exist_ok=True)
                
                # å€‹åˆ¥è©•ä¾¡çµæžœã‚’ä¿å­˜
                individual_result = {
                    'repository': repo,
                    'category': category,
                    'pr_name': pr_name,
                    'evaluation_result': result,
                    'log_path': log_path,
                    'timestamp': '$(date -Iseconds)'
                }
                
                output_file = category_dir / 'evaluation_result.json'
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(individual_result, f, indent=2, ensure_ascii=False)
                
                print(f'ðŸ“ ä¿å­˜: {output_file}')
"
        fi
        
        # è©³ç´°ãƒ­ã‚°ã‚’æ•´ç†ã—ã¦ã‚³ãƒ”ãƒ¼
        LATEST_LOG=$(ls -t /app/logs/llm_responses_*.json 2>/dev/null | head -1)
        if [ -n "${LATEST_LOG}" ]; then
            LOG_BASENAME=$(basename "${LATEST_LOG}")
            cp "${LATEST_LOG}" "${PROJECT_DETAILED_DIR}/detailed_responses_${LOG_BASENAME}"
            echo "ðŸ” è©³ç´°ãƒ­ã‚°ä¿å­˜: ${PROJECT_DETAILED_DIR}/detailed_responses_${LOG_BASENAME}"
        fi
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥ã‚µãƒžãƒªãƒ¼ä½œæˆ
        PROJECT_SUMMARY="${SUMMARY_DIR}/${PROJECT}_summary.json"
        cat > "${PROJECT_SUMMARY}" << EOF
{
  "project": "${PROJECT}",
  "evaluation_time": "${PROJECT_TIME}",
  "status": "success",
  "timestamp": "$(date -Iseconds)",
  "result_file": "${PROJECT_RESULTS_DIR}/evaluation_result_${CLEAN_NAME:-unknown}",
  "detailed_log": "${PROJECT_DETAILED_DIR}/detailed_responses_${LOG_BASENAME:-unknown}"
}
EOF
        echo "ðŸ“ˆ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒžãƒªãƒ¼: ${PROJECT_SUMMARY}"
        
    else
        PROJECT_END=$(date +%s)
        PROJECT_TIME=$((PROJECT_END - PROJECT_START))
        
        echo "âŒ ${PROJECT} è©•ä¾¡å¤±æ•— (${PROJECT_TIME}ç§’)"
        ((TOTAL_FAILED++))
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥ã«ä¿å­˜
        ERROR_DIR="${SESSION_DIR}/errors"
        mkdir -p "${ERROR_DIR}"
        ERROR_LOG="${ERROR_DIR}/${PROJECT}_error.log"
        echo "Error in ${PROJECT} at $(date -Iseconds)" >> "${ERROR_LOG}"
        echo "Duration: ${PROJECT_TIME} seconds" >> "${ERROR_LOG}"
        
        # å¤±æ•—ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚µãƒžãƒªãƒ¼ä½œæˆ
        PROJECT_SUMMARY="${SUMMARY_DIR}/${PROJECT}_summary.json"
        cat > "${PROJECT_SUMMARY}" << EOF
{
  "project": "${PROJECT}",
  "evaluation_time": "${PROJECT_TIME}",
  "status": "failed",
  "timestamp": "$(date -Iseconds)",
  "error_log": "${ERROR_LOG}"
}
EOF
        echo "âŒ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ä¿å­˜: ${ERROR_LOG}"
    fi
    
    ((TOTAL_PROCESSED++))
done

# çµ‚äº†æ™‚åˆ»è¨˜éŒ²
END_TIME=$(date +%s)
TOTAL_TIME=$((END_TIME - START_TIME))

echo "ðŸŽ‰ ================================"
echo "ðŸŽ‰ å…¨APRãƒ­ã‚°è©•ä¾¡å®Œäº†!"
echo "ðŸŽ‰ ================================"
echo "â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: ${TOTAL_TIME}ç§’ ($(($TOTAL_TIME / 60))åˆ†)"
echo "ðŸ“Š å‡¦ç†ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: ${TOTAL_PROCESSED}"
echo "âœ… æˆåŠŸ: ${TOTAL_SUCCESS}"
echo "âŒ å¤±æ•—: ${TOTAL_FAILED}"
echo "ðŸ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜å…ˆ: ${SESSION_DIR}"
echo ""

# å…¨ä½“ã‚µãƒžãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
OVERALL_SUMMARY="${SESSION_DIR}/evaluation_summary.json"
cat > "${OVERALL_SUMMARY}" << EOF
{
  "evaluation_session": {
    "timestamp": "${TIMESTAMP}",
    "start_time": "$(date -d @${START_TIME} -Iseconds)",
    "end_time": "$(date -d @${END_TIME} -Iseconds)",
    "total_duration_seconds": ${TOTAL_TIME},
    "provider": "${PROVIDER}",
    "model": "${MODEL}"
  },
  "results": {
    "total_projects_processed": ${TOTAL_PROCESSED},
    "successful_evaluations": ${TOTAL_SUCCESS},
    "failed_evaluations": ${TOTAL_FAILED},
    "success_rate": $(echo "scale=3; ${TOTAL_SUCCESS} * 100 / ${TOTAL_PROCESSED}" | bc)
  },
  "directory_structure": {
    "session_directory": "${SESSION_DIR}",
    "results_directory": "${RESULTS_DIR}",
    "detailed_responses_directory": "${DETAILED_DIR}",
    "summaries_directory": "${SUMMARY_DIR}",
    "log_file": "${LOG_FILE}"
  }
}
EOF

echo "ðŸ“Š å…¨ä½“ã‚µãƒžãƒªãƒ¼ã‚’ä¿å­˜: ${OVERALL_SUMMARY}"

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ è¡¨ç¤º
echo ""
echo "ðŸ“‚ ç”Ÿæˆã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :"
echo "â”œâ”€â”€ ${SESSION_DIR}/"
echo "â”‚   â”œâ”€â”€ full_evaluation.log                    # çµ±åˆãƒ­ã‚°"
echo "â”‚   â”œâ”€â”€ evaluation_summary.json                # å…¨ä½“ã‚µãƒžãƒªãƒ¼"
echo "â”‚   â”œâ”€â”€ results/                               # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥è©•ä¾¡çµæžœ"
echo "â”‚   â”‚   â”œâ”€â”€ boulder/"
echo "â”‚   â”‚   â”‚   â”œâ”€â”€ issue/                         # ã‚¤ã‚·ãƒ¥ãƒ¼ç¨®åˆ¥"
echo "â”‚   â”‚   â”‚   â”‚   â””â”€â”€ [issue_name]/"
echo "â”‚   â”‚   â”‚   â”‚       â””â”€â”€ evaluation_result.json"
echo "â”‚   â”‚   â”‚   â”œâ”€â”€ pullrequest/                   # ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆç¨®åˆ¥"
echo "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ [pr_name_1]/"
echo "â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ evaluation_result.json"
echo "â”‚   â”‚   â”‚   â”‚   â””â”€â”€ [pr_name_2]/"
echo "â”‚   â”‚   â”‚   â”‚       â””â”€â”€ evaluation_result.json"
echo "â”‚   â”‚   â”‚   â””â”€â”€ evaluation_result_[timestamp].json  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“çµæžœ"
echo "â”‚   â”‚   â”œâ”€â”€ daos/                              # ä»–ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"
echo "â”‚   â”‚   â”‚   â”œâ”€â”€ pullrequest/"
echo "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ [pr_name_1]/"
echo "â”‚   â”‚   â”‚   â”‚   â””â”€â”€ [pr_name_2]/"
echo "â”‚   â”‚   â”‚   â””â”€â”€ evaluation_result_[timestamp].json"
echo "â”‚   â”‚   â””â”€â”€ [ä»–ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ]/"
echo "â”‚   â”œâ”€â”€ detailed_responses/                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥è©³ç´°ãƒ¬ã‚¹ãƒãƒ³ã‚¹"
echo "â”‚   â”‚   â”œâ”€â”€ boulder/detailed_responses_[timestamp].json"
echo "â”‚   â”‚   â”œâ”€â”€ daos/detailed_responses_[timestamp].json"
echo "â”‚   â”‚   â””â”€â”€ [ä»–ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ]/detailed_responses_[timestamp].json"
echo "â”‚   â”œâ”€â”€ summaries/                             # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥ã‚µãƒžãƒªãƒ¼"
echo "â”‚   â”‚   â”œâ”€â”€ boulder_summary.json"
echo "â”‚   â”‚   â”œâ”€â”€ daos_summary.json"
echo "â”‚   â”‚   â””â”€â”€ [ä»–ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ]_summary.json"
echo "â”‚   â””â”€â”€ errors/                                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ï¼ˆå¤±æ•—æ™‚ã®ã¿ï¼‰"
echo "â”‚       â”œâ”€â”€ [project]_error.log"
echo "â”‚       â””â”€â”€ ..."
echo ""
echo "ðŸ“ˆ çµæžœç¢ºèªæ–¹æ³•:"
echo "  ls -la ${SESSION_DIR}/"
echo "  find ${SESSION_DIR}/results -name '*.json' | head -10"
echo "  python scripts/evaluation_log_viewer.py --latest"
echo "  cat ${OVERALL_SUMMARY}"
echo ""
echo "ðŸŽ¯ ã™ã¹ã¦ã®è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
