#!/usr/bin/env python3
"""
APRã‚¿ã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªåˆ†é¡žæ”¯æ´ãƒ„ãƒ¼ãƒ«
ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰è‡ªå‹•åˆ†é¡žã—ã€æ‰‹å‹•ç¢ºèªãƒ»ä¿®æ­£ã‚’æ”¯æ´
"""

import json
import pandas as pd
import re
from pathlib import Path
from typing import Dict, List, Tuple
import logging


class TaskCategoryClassifier:
    """ã‚¿ã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªåˆ†é¡žå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # æ‹¡å¼µã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾žæ›¸
        self.category_patterns = {
            'ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°': {
                'keywords': ['refactor', 'rename', 'restructure', 'reorganize', 'move', 'extract', 
                           'relocate', 'cleanup', 'simplify', 'consolidate'],
                'patterns': [r'\bmove\s+\w+\s+to\b', r'\brename\s+\w+', r'\bextract\s+\w+']
            },
            'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æ”¹å–„': {
                'keywords': ['performance', 'optimize', 'cache', 'index', 'speed', 'efficient', 
                           'faster', 'improve', 'accelerate', 'benchmark'],
                'patterns': [r'\boptimize\b', r'\bperformance\b', r'\bspeed\s+up\b']
            },
            'æ©Ÿèƒ½è¿½åŠ ': {
                'keywords': ['add', 'implement', 'feature', 'endpoint', 'api', 'support', 
                           'introduce', 'create', 'new', 'enhance'],
                'patterns': [r'\badd\s+\w+', r'\bimplement\s+\w+', r'\bnew\s+\w+']
            },
            'ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰': {
                'keywords': ['test', 'unittest', 'integration', 'coverage', 'mock', 'spec', 
                           'testing', 'verification', 'validate'],
                'patterns': [r'\btest\s+\w+', r'\bunittest\b', r'\bmock\s+\w+']
            },
            'ãƒã‚°ä¿®æ­£': {
                'keywords': ['fix', 'bug', 'error', 'issue', 'correct', 'resolve', 'repair', 
                           'patch', 'address', 'handle'],
                'patterns': [r'\bfix\s+\w+', r'\bbug\s+fix\b', r'\bresolve\s+\w+']
            },
            'å˜ç´”ä¿®æ­£': {
                'keywords': ['typo', 'license', 'header', 'format', 'style', 'comment', 
                           'whitespace', 'indent', 'spelling'],
                'patterns': [r'\btypo\b', r'\blicense\s+header\b', r'\bformat\s+\w+']
            },
            'ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ': {
                'keywords': ['doc', 'readme', 'documentation', 'comment', 'example', 
                           'guide', 'manual', 'explain'],
                'patterns': [r'\bdoc\s+\w+', r'\breadme\b', r'\bdocumentation\b']
            },
            'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': {
                'keywords': ['security', 'auth', 'permission', 'vulnerability', 'secure', 
                           'encrypt', 'protect', 'certificate', 'tls', 'ssl'],
                'patterns': [r'\bsecurity\s+\w+', r'\bauth\w*', r'\bssl\b', r'\btls\b']
            },
            'ä¾å­˜é–¢ä¿‚': {
                'keywords': ['dependency', 'update', 'version', 'upgrade', 'package', 
                           'library', 'framework', 'module'],
                'patterns': [r'\bupdate\s+\w+', r'\bupgrade\s+\w+', r'\bdependency\b']
            },
            'è¨­å®šãƒ»ç’°å¢ƒ': {
                'keywords': ['config', 'environment', 'setup', 'install', 'deploy', 
                           'configuration', 'setting', 'env'],
                'patterns': [r'\bconfig\w*', r'\bsetup\b', r'\benvironment\b']
            },
            'ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ»é€šä¿¡': {
                'keywords': ['grpc', 'http', 'api', 'protocol', 'endpoint', 'request', 
                           'response', 'client', 'server'],
                'patterns': [r'\bgrpc\b', r'\bhttp\s+\w+', r'\bapi\s+\w+']
            },
            'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹': {
                'keywords': ['database', 'sql', 'query', 'table', 'schema', 'migration', 
                           'index', 'db'],
                'patterns': [r'\bdatabase\b', r'\bsql\b', r'\bquery\b', r'\btable\b']
            }
        }

    def classify_task(self, task_title: str, experiment_id: str = "") -> Tuple[str, float]:
        """
        ã‚¿ã‚¹ã‚¯ã‚’åˆ†é¡žã—ã€ä¿¡é ¼åº¦ã‚’è¿”ã™
        
        Returns:
            (category, confidence): ã‚«ãƒ†ã‚´ãƒªåã¨ä¿¡é ¼åº¦(0.0-1.0)
        """
        task_lower = task_title.lower()
        experiment_lower = experiment_id.lower()
        combined_text = f"{task_lower} {experiment_lower}"
        
        category_scores = {}
        
        for category, patterns in self.category_patterns.items():
            score = 0.0
            matches = 0
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒžãƒƒãƒãƒ³ã‚°
            for keyword in patterns['keywords']:
                if keyword in combined_text:
                    score += 1.0
                    matches += 1
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒžãƒƒãƒãƒ³ã‚°ï¼ˆã‚ˆã‚Šé«˜ã„é‡ã¿ï¼‰
            for pattern in patterns['patterns']:
                if re.search(pattern, combined_text, re.IGNORECASE):
                    score += 2.0
                    matches += 1
            
            # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆãƒžãƒƒãƒæ•°ã«åŸºã¥ãï¼‰
            if matches > 0:
                max_possible = len(patterns['keywords']) + len(patterns['patterns']) * 2
                confidence = min(score / max_possible, 1.0)
                category_scores[category] = confidence
        
        if not category_scores:
            return "ãã®ä»–", 0.0
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠž
        best_category = max(category_scores.keys(), key=lambda k: category_scores[k])
        best_confidence = category_scores[best_category]
        
        return best_category, best_confidence

    def batch_classify_from_session(self, session_path: str) -> pd.DataFrame:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸€æ‹¬åˆ†é¡ž"""
        session_dir = Path(session_path)
        results_dir = session_dir / "results"
        
        all_tasks = []
        
        # å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’æŠ½å‡º
        for project_dir in results_dir.iterdir():
            if not project_dir.is_dir():
                continue
                
            project_name = project_dir.name
            result_files = list(project_dir.glob("evaluation_result_*.json"))
            
            if not result_files:
                continue
            
            # æœ€æ–°ã®çµæžœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
            result_file = max(result_files, key=lambda x: x.stat().st_mtime)
            
            try:
                with open(result_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                analysis_data = data.get('Real_OPENAI_Analysis', {})
                detailed_results = analysis_data.get('detailed_results', [])
                
                for result in detailed_results:
                    experiment_id = result.get('experiment_id', '')
                    
                    # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
                    if '/Issue_' in experiment_id:
                        task_type = 'issue'
                        task_title = experiment_id.split('/Issue_')[1].replace('_', ' ')
                    elif '/PR_' in experiment_id:
                        task_type = 'pullrequest'
                        task_title = experiment_id.split('/PR_')[1].replace('_', ' ')
                    else:
                        task_type = 'unknown'
                        task_title = experiment_id.split('/')[-1].replace('_', ' ')
                    
                    # è‡ªå‹•åˆ†é¡žå®Ÿè¡Œ
                    category, confidence = self.classify_task(task_title, experiment_id)
                    
                    all_tasks.append({
                        'project': project_name,
                        'experiment_id': experiment_id,
                        'task_type': task_type,
                        'task_title': task_title,
                        'auto_category': category,
                        'confidence': confidence,
                        'manual_category': '',  # æ‰‹å‹•ç¢ºèªç”¨
                        'notes': ''  # ãƒ¡ãƒ¢ç”¨
                    })
                    
            except Exception as e:
                self.logger.error(f"âŒ {project_name}: {e}")
        
        return pd.DataFrame(all_tasks)

    def export_classification_template(self, df: pd.DataFrame, output_path: str) -> None:
        """åˆ†é¡žç¢ºèªç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆä½Žã„é †ï¼‰
        df_sorted = df.sort_values(['confidence', 'project', 'task_title'])
        
        # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆã‚’è¿½åŠ 
        category_stats = df.groupby('auto_category').agg({
            'confidence': ['count', 'mean', 'std'],
            'project': 'nunique'
        }).round(3)
        
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # ãƒ¡ã‚¤ãƒ³åˆ†é¡žãƒ‡ãƒ¼ã‚¿
            df_sorted.to_excel(writer, sheet_name='Task_Classification', index=False)
            
            # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
            category_stats.to_excel(writer, sheet_name='Category_Statistics')
            
            # åˆ†é¡žã‚¬ã‚¤ãƒ‰
            guide_data = []
            for category, patterns in self.category_patterns.items():
                guide_data.append({
                    'Category': category,
                    'Keywords': ', '.join(patterns['keywords'][:5]),  # æœ€åˆã®5å€‹
                    'Description': f"{len(patterns['keywords'])} keywords, {len(patterns['patterns'])} patterns"
                })
            
            pd.DataFrame(guide_data).to_excel(writer, sheet_name='Classification_Guide', index=False)
        
        print(f"âœ… åˆ†é¡žãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å‡ºåŠ›: {output_path}")
        print(f"ðŸ“Š ç·ã‚¿ã‚¹ã‚¯æ•°: {len(df):,}")
        print(f"ðŸ·ï¸ è‡ªå‹•åˆ†é¡žã‚«ãƒ†ã‚´ãƒªæ•°: {df['auto_category'].nunique()}")
        print(f"ðŸ“ˆ å¹³å‡ä¿¡é ¼åº¦: {df['confidence'].mean():.3f}")

    def generate_classification_report(self, df: pd.DataFrame) -> str:
        """åˆ†é¡žãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = []
        report.append("# APR Task Classification Report")
        report.append(f"**ç·ã‚¿ã‚¹ã‚¯æ•°**: {len(df):,}")
        report.append(f"**åˆ†æžæ—¥æ™‚**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        report.append("## ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ")
        report.append("")
        category_stats = df.groupby('auto_category').agg({
            'confidence': ['count', 'mean', 'std'],
            'project': 'nunique'
        }).round(3)
        
        report.append("| ã‚«ãƒ†ã‚´ãƒª | ä»¶æ•° | å¹³å‡ä¿¡é ¼åº¦ | ä¿¡é ¼åº¦æ¨™æº–åå·® | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•° |")
        report.append("|---------|------|-----------|--------------|---------------|")
        
        for category in category_stats.index:
            count = category_stats.loc[category, ('confidence', 'count')]
            mean_conf = category_stats.loc[category, ('confidence', 'mean')]
            std_conf = category_stats.loc[category, ('confidence', 'std')]
            project_count = category_stats.loc[category, ('project', 'nunique')]
            
            report.append(f"| {category} | {count} | {mean_conf:.3f} | {std_conf:.3f} | {project_count} |")
        
        report.append("")
        
        # ä¿¡é ¼åº¦åˆ†æž
        report.append("## ä¿¡é ¼åº¦åˆ†æž")
        report.append("")
        
        high_conf = len(df[df['confidence'] >= 0.7])
        medium_conf = len(df[(df['confidence'] >= 0.3) & (df['confidence'] < 0.7)])
        low_conf = len(df[df['confidence'] < 0.3])
        
        report.append(f"- **é«˜ä¿¡é ¼åº¦** (â‰¥0.7): {high_conf:,}ä»¶ ({high_conf/len(df)*100:.1f}%)")
        report.append(f"- **ä¸­ä¿¡é ¼åº¦** (0.3-0.7): {medium_conf:,}ä»¶ ({medium_conf/len(df)*100:.1f}%)")
        report.append(f"- **ä½Žä¿¡é ¼åº¦** (<0.3): {low_conf:,}ä»¶ ({low_conf/len(df)*100:.1f}%)")
        report.append("")
        
        # è¦ç¢ºèªé …ç›®
        report.append("## è¦ç¢ºèªé …ç›®")
        report.append("")
        
        low_confidence_tasks = df[df['confidence'] < 0.3].head(10)
        if not low_confidence_tasks.empty:
            report.append("### ä¿¡é ¼åº¦ãŒä½Žã„ã‚¿ã‚¹ã‚¯ï¼ˆä¸Šä½10ä»¶ï¼‰")
            report.append("")
            for _, task in low_confidence_tasks.iterrows():
                report.append(f"- **{task['project']}**: {task['task_title']} (ä¿¡é ¼åº¦: {task['confidence']:.3f})")
            report.append("")
        
        return '\n'.join(report)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='APR Task Category Classification Tool')
    parser.add_argument('session_path', help='è©•ä¾¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ‘ã‚¹')
    parser.add_argument('--output', '-o', default='./classification_output', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    args = parser.parse_args()
    
    # åˆ†é¡žå™¨åˆæœŸåŒ–
    classifier = TaskCategoryClassifier()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
    output_dir = Path(args.output)
    output_dir.mkdir(exist_ok=True)
    
    try:
        # ä¸€æ‹¬åˆ†é¡žå®Ÿè¡Œ
        print("ðŸ” ã‚¿ã‚¹ã‚¯åˆ†é¡žé–‹å§‹...")
        df = classifier.batch_classify_from_session(args.session_path)
        
        # åˆ†é¡žãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        template_path = output_dir / 'task_classification_template.xlsx'
        classifier.export_classification_template(df, str(template_path))
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = classifier.generate_classification_report(df)
        report_path = output_dir / 'classification_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ðŸ“„ åˆ†é¡žãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›: {report_path}")
        print(f"ðŸŽ‰ åˆ†é¡žå®Œäº†ï¼çµæžœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        
    except Exception as e:
        print(f"âŒ åˆ†é¡žã‚¨ãƒ©ãƒ¼: {e}")
        raise


if __name__ == "__main__":
    main()
