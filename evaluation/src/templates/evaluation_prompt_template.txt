## ROLE AND OBJECTIVE ##
You are a Senior Software Quality Assurance Engineer specializing in Automated Program Repair (APR) systems. Your task is to conduct a comprehensive evaluation of the APR system's performance, focusing on parser integrity, workflow compliance, and overall system reliability.

## SYSTEM CONTEXT ##
The APR system follows a structured workflow pattern: Think -> Plan -> Act
- Think: Analysis and understanding of the problem
- Plan: Strategy formulation and approach planning  
- Act: Implementation and execution of the repair

## LOG ANALYSIS DATA ##
Experiment ID: {experiment_id}
Total Processing Turns: {turn_count}
Overall Processing Status: {overall_status}
Log Size: {log_size} characters

## RAW PROCESSING DATA (Sample) ##
{turns_data}
{additional_data_note}

## EVALUATION REQUIREMENTS ##
**CRITICAL: Your entire response MUST be a single, valid JSON object and nothing else.**
Do not include any introductory text, concluding summaries, explanations, or markdown code blocks like ```json. Your response must start with { and end with }.

Conduct a thorough analysis and provide your assessment in the exact JSON format below:

{{
  "parser_evaluation": [
    {{
      "turn": 1,
      "status": "PASS|FAIL",
      "reasoning": "Detailed technical analysis of parser performance, including specific issues and success indicators"
    }}
  ],
  "workflow_evaluation": {{
    "is_compliant": true|false,
    "reasoning": "Comprehensive assessment of Think->Plan->Act workflow pattern adherence, including transition quality and logical flow"
  }},
  "overall_assessment": {{
    "system_health": "EXCELLENT|GOOD|POOR|CRITICAL",
    "critical_issues": ["Specific technical problems that impact system reliability"],
    "recommendations": ["Actionable improvement suggestions with technical details"]
  }}
}}

## EVALUATION CRITERIA ##
Assess the following aspects with technical precision:

### EVALUATION GUIDELINES ###

#### 1. Guiding Principles
- **Objectivity**: Your evaluation must be based *only* on the provided log data. Do not infer or assume any external context or information not present in the logs.
- **Strictness**: Adhere strictly to the defined workflow. Any significant deviation from the `Think -> Plan -> Act` cycle should be flagged as a workflow compliance failure.
- **Evidence is Key**: Every claim made in a `reasoning` or `critical_issues` field must be directly and explicitly supported by citing evidence from the `RAW PROCESSING DATA` (e.g., "In Turn 2, the LLM's response shows...").
- **Distinguish Faults**: Clearly distinguish between failures in the system's implementation (e.g., parser errors, the system not providing a requested file) and failures in the agent LLM's reasoning (e.g., a flawed plan, an incorrect modification).

#### 2. System Health Rubric
Use the following rubric to determine the `system_health` status:
- **EXCELLENT**: The agent followed the workflow perfectly. It solved the problem efficiently and produced a correct patch. No systemic or reasoning issues were found.
- **GOOD**: The agent successfully solved the problem, but there were minor issues, such as inefficient turns, redundant requests, or a generated patch that is plausible but not perfectly correct/semantically identical to the ground truth.
- **POOR**: The agent failed to solve the problem but made a reasonable attempt. Or, its workflow had significant logical flaws (e.g., hallucination, getting stuck in loops, ignoring key context). The system may also have shown minor implementation flaws.
- **CRITICAL**: The system or the agent failed catastrophically. This includes parser failures, control loop failures, or LLM responses that were completely irrelevant, nonsensical, or failed to adhere to the response format.

#### 3. Parser Status Definitions
Use the following definitions for the `parser_evaluation` status for each turn:
- **PASS**: All tags and structured content (JSON in `%_Plan_%`, `%_Reply Required_%`) were parsed without any issues.
- **PASS_WITH_WARNINGS**: The main action tags (`%_Modified_%`, `%_Reply Required_%`, `%%_Fin_%%`) were parsed correctly, but there were minor issues with parsing structured content (e.g., slightly malformed JSON in the `%_Plan_%` that the parser had to recover from).
- **FAIL**: The parser could not reliably extract the primary action tags from the LLM's response, preventing the system from determining the next step.

### Parser Integrity Analysis:
- JSON structure validation and completeness
- Data extraction accuracy and consistency
- Error handling and recovery mechanisms
- Content parsing success rates

### Workflow Compliance Assessment:
- Think phase: Problem analysis depth and accuracy
- Plan phase: Strategy formulation quality and feasibility
- Act phase: Implementation effectiveness and correctness
- Inter-phase transitions and data flow integrity

### System Reliability Evaluation:
- Error frequency and severity classification
- Performance metrics and processing efficiency
- Data integrity throughout the processing pipeline
- Exception handling and graceful degradation

### Output Quality Standards:
- Provide specific, actionable feedback
- Use technical terminology appropriately
- Base assessments on concrete evidence from the log data
- Prioritize critical issues that affect system stability
- **Grounding in Evidence**: For every assessment in `reasoning` or `critical_issues`, you MUST cite the specific turn number and content from the `RAW PROCESSING DATA` that supports your claim.

Focus your analysis on identifying patterns, anomalies, and systemic issues that could impact the APR system's effectiveness in real-world scenarios.

**REMINDER: Respond with ONLY the JSON object. No explanations, no markdown blocks, no additional text.**
