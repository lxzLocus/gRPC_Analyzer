/**
 * å¯¾è©±å±¥æ­´è¦ç´„ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
 * é•·ã„å¯¾è©±å±¥æ­´ã‚’å‹•çš„ã«è¦ç´„ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™ã‚’å›é¿ã™ã‚‹
 * 
 * 4å±¤ãƒˆãƒªã‚¬ãƒ¼ã‚·ã‚¹ãƒ†ãƒ :
 * 1. TOKEN_THRESHOLD: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ æ™‚ã®ãƒˆãƒ¼ã‚¯ãƒ³é–¾å€¤ãƒã‚§ãƒƒã‚¯
 * 2. PRE_SEND_CHECK: LLMé€ä¿¡ç›´å‰ã®æœ€çµ‚å®‰å…¨ãƒã‚§ãƒƒã‚¯
 * 3. TURN_COMPLETION: ã‚¿ãƒ¼ãƒ³å®Œäº†æ™‚ã®éåŒæœŸè¦ç´„
 * 4. TASK_COMPLETION: ã‚¿ã‚¹ã‚¯å®Œäº†æ™‚ã®ãƒ¡ã‚¿è¦ç´„
 */

import type { 
    ConversationSummary, 
    ConversationHistoryManager, 
    SummarizeRequest, 
    SummarizeResponse,
    SummarizationTriggerType
} from './types.js';
import Config from './config.js';
import OpenAIClient from './openAIClient.js';

class ConversationSummarizer {
    private config: Config;
    private openAIClient: OpenAIClient;
    private historyManager: ConversationHistoryManager;
    private correctionGoalsCallback: () => string; // correctionGoalsã‚’å–å¾—ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    // è¨­å®š
    private readonly DEFAULT_SUMMARY_THRESHOLD = 30000; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³é–¾å€¤
    private readonly TOKEN_ESTIMATION_RATIO = 4; // 1ãƒˆãƒ¼ã‚¯ãƒ³ â‰ˆ 4æ–‡å­—ã®è¿‘ä¼¼
    private readonly MODEL_HARD_LIMIT = 100000; // ãƒ¢ãƒ‡ãƒ«ã®çµ¶å¯¾ä¸Šé™ï¼ˆç·Šæ€¥è¦ç´„ãƒˆãƒªã‚¬ãƒ¼ï¼‰
    private readonly MIN_TURN_INTERVAL = 3; // æœ€å°è¦ç´„é–“éš”ï¼ˆå‹•çš„èª¿æ•´å¯èƒ½ï¼‰
    private readonly TOKEN_GROWTH_THRESHOLD = 1.4; // ãƒˆãƒ¼ã‚¯ãƒ³æˆé•·ç‡é–¾å€¤

    constructor(config: Config, openAIClient: OpenAIClient, correctionGoalsCallback: () => string) {
        this.config = config;
        this.openAIClient = openAIClient;
        this.correctionGoalsCallback = correctionGoalsCallback;
        
        this.historyManager = {
            messages: [],
            totalTokens: 0,
            summaryThreshold: this.config.get('llm.summaryThreshold', this.DEFAULT_SUMMARY_THRESHOLD),
            lastSummaryTurn: 0,
            summaryTokensUsed: 0,
            lastTokenAtSummary: 0,
            summarizationHistory: []
        };
        
        console.log(`ğŸ“ ConversationSummarizer initialized with threshold: ${this.historyManager.summaryThreshold} tokens`);
    }

    /**
     * ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ ã—ã€å¿…è¦ã«å¿œã˜ã¦è¦ç´„ã‚’å®Ÿè¡Œ
     * ãƒˆãƒªã‚¬ãƒ¼å±¤1: TOKEN_THRESHOLD
     */
    async addMessage(role: string, content: string): Promise<Array<{ role: string, content: string }>> {
        // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        this.historyManager.messages.push({ role, content });
        
        // ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ›´æ–°
        this.updateTokenCount();
        
        console.log(`ğŸ“Š Current conversation: ${this.historyManager.messages.length} messages, ~${this.historyManager.totalTokens} tokens`);
        
        // ãƒˆãƒªã‚¬ãƒ¼å±¤1: ãƒˆãƒ¼ã‚¯ãƒ³é–¾å€¤ãƒã‚§ãƒƒã‚¯ï¼ˆå‹•çš„é–“éš”èª¿æ•´ä»˜ãï¼‰
        if (this.shouldSummarize('TOKEN_THRESHOLD')) {
            console.log(`ğŸ”„ [Trigger 1] Token threshold exceeded, starting dynamic summarization...`);
            return await this.performDynamicSummarization('TOKEN_THRESHOLD', 'Token count exceeded threshold');
        }
        
        return this.historyManager.messages;
    }

    /**
     * LLMé€ä¿¡ç›´å‰ã®æœ€çµ‚å®‰å…¨ãƒã‚§ãƒƒã‚¯
     * ãƒˆãƒªã‚¬ãƒ¼å±¤2: PRE_SEND_CHECK
     */
    async preSendCheck(): Promise<Array<{ role: string, content: string }>> {
        // ãƒ¢ãƒ‡ãƒ«ã®çµ¶å¯¾ä¸Šé™ãƒã‚§ãƒƒã‚¯
        if (this.historyManager.totalTokens > this.MODEL_HARD_LIMIT) {
            console.log(`âš ï¸ [Trigger 2] Hard limit reached (${this.historyManager.totalTokens} > ${this.MODEL_HARD_LIMIT}), forcing compression...`);
            return await this.performDynamicSummarization('PRE_SEND_CHECK', 'Emergency: Model hard limit exceeded');
        }
        
        // é–¾å€¤è¶…éã—ã¦ã„ã‚‹ãŒå‰å›è¦ç´„ãŒæœ€è¿‘ã™ããŸå ´åˆã®å†ãƒã‚§ãƒƒã‚¯
        if (this.historyManager.totalTokens > this.historyManager.summaryThreshold * 0.9) {
            const messagesSinceLastSummary = this.historyManager.messages.length - this.historyManager.lastSummaryTurn;
            if (messagesSinceLastSummary >= 2) { // æœ€å°é–“éš”ç·©å’Œ
                console.log(`ğŸ” [Trigger 2] Pre-send safety check triggered (${this.historyManager.totalTokens} tokens, ${messagesSinceLastSummary} messages since last summary)`);
                return await this.performDynamicSummarization('PRE_SEND_CHECK', 'Pre-send safety check');
            }
        }
        
        return this.historyManager.messages;
    }

    /**
     * ã‚¿ãƒ¼ãƒ³å®Œäº†æ™‚ã®è¦ç´„ãƒã‚§ãƒƒã‚¯
     * ãƒˆãƒªã‚¬ãƒ¼å±¤3: TURN_COMPLETION
     */
    async onTurnComplete(turnNumber: number): Promise<void> {
        // ä¸€å®šã‚¿ãƒ¼ãƒ³æ•°ã”ã¨ã®è¦ç´„ãƒã‚§ãƒƒã‚¯
        if (turnNumber % 5 === 0 && turnNumber > 0) {
            const messagesSinceLastSummary = this.historyManager.messages.length - this.historyManager.lastSummaryTurn;
            if (messagesSinceLastSummary >= 5 && this.historyManager.totalTokens > this.historyManager.summaryThreshold * 0.7) {
                console.log(`ğŸ”„ [Trigger 3] Turn completion check (Turn ${turnNumber}, preparing for next phase)`);
                // éåŒæœŸè¦ç´„ï¼ˆæ¬¡ã‚¿ãƒ¼ãƒ³æº–å‚™ï¼‰
                await this.performDynamicSummarization('TURN_COMPLETION', `Turn ${turnNumber} completed`);
            }
        }
    }

    /**
     * ã‚¿ã‚¹ã‚¯å®Œäº†æ™‚ã®ãƒ¡ã‚¿è¦ç´„
     * ãƒˆãƒªã‚¬ãƒ¼å±¤4: TASK_COMPLETION
     */
    async onTaskComplete(taskName: string): Promise<ConversationSummary | null> {
        if (this.historyManager.messages.length > 0) {
            console.log(`ğŸ“‹ [Trigger 4] Task completion meta-summary for: ${taskName}`);
            
            // ãƒ¡ã‚¿è¦ç´„ã‚’ç”Ÿæˆï¼ˆæ¬¡ã‚¿ã‚¹ã‚¯ã¸ã®å¼•ãç¶™ãç”¨ï¼‰
            const conversationHistory = this.formatConversationForSummary();
            const summarizePrompt = this.config.readPromptSummarizeFile(conversationHistory);
            
            const summaryResponse = await this.generateSummary({
                fullConversationHistory: summarizePrompt,
                model: this.config.get('llm.summaryModel', this.config.get('llm.model', 'gpt-4')),
                temperature: 0.1
            });
            
            if (summaryResponse.success) {
                // è¦ç´„å±¥æ­´ã«è¨˜éŒ²
                this.recordSummarization('TASK_COMPLETION', `Task completed: ${taskName}`, this.historyManager.totalTokens, this.historyManager.messages.length);
                return summaryResponse.summary;
            }
        }
        
        return null;
    }

    /**
     * ç¾åœ¨ã®å¯¾è©±å±¥æ­´ã‚’å–å¾—
     */
    getCurrentMessages(): Array<{ role: string, content: string }> {
        return this.historyManager.messages;
    }

    /**
     * è¦ç´„å±¥æ­´ã‚’å–å¾—
     */
    getSummarizationHistory() {
        return this.historyManager.summarizationHistory;
    }

    /**
     * è¦ç´„çµ±è¨ˆã‚’å–å¾—
     */
    getSummarizationStats() {
        return {
            totalSummarizations: this.historyManager.summarizationHistory.length,
            summaryTokensUsed: this.historyManager.summaryTokensUsed,
            currentTokens: this.historyManager.totalTokens,
            lastSummaryTurn: this.historyManager.lastSummaryTurn,
            triggers: this.historyManager.summarizationHistory.reduce((acc, item) => {
                acc[item.type] = (acc[item.type] || 0) + 1;
                return acc;
            }, {} as Record<SummarizationTriggerType, number>)
        };
    }

    /**
     * ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¨å®šå€¤ã‚’æ›´æ–°
     */
    private updateTokenCount(): void {
        const totalText = this.historyManager.messages
            .map(msg => msg.content)
            .join(' ');
        
        // ç°¡æ˜“çš„ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®šï¼ˆå®Ÿéš›ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ã¯å¤šå°‘ç•°ãªã‚‹ï¼‰
        this.historyManager.totalTokens = Math.ceil(totalText.length / this.TOKEN_ESTIMATION_RATIO);
    }

    /**
     * è¦ç´„ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆå‹•çš„é–“éš”èª¿æ•´ä»˜ãï¼‰
     */
    private shouldSummarize(triggerType: SummarizationTriggerType): boolean {
        const exceedsThreshold = this.historyManager.totalTokens > this.historyManager.summaryThreshold;
        const messagesSinceLastSummary = this.historyManager.messages.length - this.historyManager.lastSummaryTurn;
        
        // ãƒˆãƒ¼ã‚¯ãƒ³æˆé•·ç‡ã‚’è¨ˆç®—
        let tokenGrowthRate = 1.0;
        if (this.historyManager.lastTokenAtSummary > 0) {
            tokenGrowthRate = this.historyManager.totalTokens / this.historyManager.lastTokenAtSummary;
        }
        
        // å‹•çš„é–“éš”èª¿æ•´: æˆé•·ç‡ãŒé«˜ã„å ´åˆã¯æ—©ã‚ã«è¦ç´„
        let minInterval = this.MIN_TURN_INTERVAL;
        if (tokenGrowthRate > this.TOKEN_GROWTH_THRESHOLD) {
            minInterval = Math.max(2, this.MIN_TURN_INTERVAL - 1);
            console.log(`ğŸ“ˆ High token growth rate detected: ${tokenGrowthRate.toFixed(2)}x, reducing interval to ${minInterval}`);
        } else if (tokenGrowthRate < 1.2) {
            minInterval = this.MIN_TURN_INTERVAL + 2;
        }
        
        const enoughMessagesSinceLastSummary = messagesSinceLastSummary >= minInterval;
        
        return exceedsThreshold && enoughMessagesSinceLastSummary;
    }

    /**
     * è¦ç´„å±¥æ­´ã‚’è¨˜éŒ²
     */
    private recordSummarization(
        type: SummarizationTriggerType,
        reason: string,
        tokenCount: number,
        messageCount: number
    ): void {
        this.historyManager.summarizationHistory.push({
            type,
            reason,
            timestamp: new Date().toISOString(),
            tokenCount,
            messageCount
        });
        
        console.log(`ğŸ“Š Summarization recorded: [${type}] ${reason} (${tokenCount} tokens, ${messageCount} messages)`);
    }

    /**
     * å‹•çš„è¦ç´„ã®å®Ÿè¡Œ
     */
    private async performDynamicSummarization(
        triggerType: SummarizationTriggerType,
        reason: string
    ): Promise<Array<{ role: string, content: string }>> {
        try {
            const beforeTokens = this.historyManager.totalTokens;
            const beforeMessages = this.historyManager.messages.length;
            
            // 1. è¦ç´„ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            const conversationHistory = this.formatConversationForSummary();
            const summarizePrompt = this.config.readPromptSummarizeFile(conversationHistory);
            
            console.log(`ğŸ“ Sending ${summarizePrompt.length} characters to summarization...`);
            console.log(`   Trigger: [${triggerType}] ${reason}`);
            
            // 2. åˆ¥ã®LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§è¦ç´„ã‚’ç”Ÿæˆ
            const summaryResponse = await this.generateSummary({
                fullConversationHistory: summarizePrompt,
                model: this.config.get('llm.summaryModel', this.config.get('llm.model', 'gpt-4')),
                temperature: 0.1 // è¦ç´„ã«ã¯ä½ã„æ¸©åº¦ã‚’ä½¿ç”¨
            });
            
            if (!summaryResponse.success) {
                console.error(`âŒ Summarization failed: ${summaryResponse.error}`);
                return this.historyManager.messages; // è¦ç´„å¤±æ•—æ™‚ã¯å…ƒã®å±¥æ­´ã‚’è¿”ã™
            }
            
            // 3. æœ€å¾Œã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®çµæœã‚’ç‰¹å®š
            const lastActionResult = this.extractLastActionResult();
            
            // 4. å¯¾è©±å†é–‹ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            const correctionGoals = this.correctionGoalsCallback();
            const resumePrompt = this.config.readPromptResumeFromSummaryFile(
                JSON.stringify(summaryResponse.summary, null, 2),
                lastActionResult,
                correctionGoals
            );
            
            // 5. æ–°ã—ã„çŸ­ã„å¯¾è©±å±¥æ­´ã«ç½®ãæ›ãˆï¼ˆãŸã ã—ã€ç›´å‰ã«è¿½åŠ ã•ã‚ŒãŸæœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ä¿æŒï¼‰
            const systemMessage = this.historyManager.messages.find(msg => msg.role === 'system');
            
            // è¦ç´„ãŒç™ºå‹•ã™ã‚‹ç›´å‰ã«è¿½åŠ ã•ã‚ŒãŸæœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿æŒï¼ˆé€šå¸¸ã¯ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼‰
            // ã“ã‚Œã«ã‚ˆã‚Šã€Turn 2ã§ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒå¤±ã‚ã‚Œã‚‹ãƒã‚°ã‚’é˜²ã
            const lastMessage = this.historyManager.messages[this.historyManager.messages.length - 1];
            
            this.historyManager.messages = [
                ...(systemMessage ? [systemMessage] : []),
                { role: 'user', content: resumePrompt },
                lastMessage  // æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãªã©ï¼‰ã‚’ä¿æŒ
            ];
            
            // 6. çµ±è¨ˆã‚’æ›´æ–°
            this.historyManager.lastTokenAtSummary = beforeTokens; // æˆé•·ç‡è¨ˆç®—ç”¨ã«ä¿å­˜
            this.historyManager.lastSummaryTurn = this.historyManager.messages.length;
            this.updateTokenCount();
            
            // è¦ç´„å±¥æ­´ã‚’è¨˜éŒ²
            this.recordSummarization(triggerType, reason, beforeTokens, beforeMessages);
            
            const reductionRate = Math.round((1 - this.historyManager.totalTokens / beforeTokens) * 100);
            
            console.log(`âœ… Dynamic summarization completed:`);
            console.log(`   Trigger: [${triggerType}] ${reason}`);
            console.log(`   Original: ${beforeTokens} tokens, ${beforeMessages} messages`);
            console.log(`   Compressed: ${this.historyManager.totalTokens} tokens, ${this.historyManager.messages.length} messages`);
            console.log(`   Reduction: ${reductionRate}%`);
            
            return this.historyManager.messages;
            
        } catch (error) {
            console.error(`âŒ Error during dynamic summarization:`, error);
            return this.historyManager.messages; // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®å±¥æ­´ã‚’ä¿æŒ
        }
    }

    /**
     * è¦ç´„ç”¨ã«å¯¾è©±å±¥æ­´ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
     */
    private formatConversationForSummary(): string {
        return this.historyManager.messages
            .map((msg, index) => `[Turn ${index + 1}] ${msg.role.toUpperCase()}: ${msg.content}`)
            .join('\n\n');
    }

    /**
     * LLMã«è¦ç´„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
     */
    private async generateSummary(request: SummarizeRequest): Promise<SummarizeResponse> {
        try {
            const summarizeMessages = [
                {
                    role: 'system',
                    content: 'You are a specialized AI assistant for summarizing technical conversations about code modifications.'
                },
                {
                    role: 'user',
                    content: request.fullConversationHistory
                }
            ];
            
            const response = await this.openAIClient.fetchOpenAPI(summarizeMessages);
            
            if (response && response.choices && response.choices[0]) {
                const summaryText = response.choices[0].message.content.trim();
                
                // è¦ç´„ã§æ¶ˆè²»ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨˜éŒ²
                const summaryUsage = response.usage || { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 };
                this.historyManager.summaryTokensUsed += summaryUsage.total_tokens;
                
                console.log(`ğŸ“Š Summary API usage - Prompt: ${summaryUsage.prompt_tokens}, Completion: ${summaryUsage.completion_tokens}, Total: ${summaryUsage.total_tokens}`);
                console.log(`ğŸ“Š Cumulative summary tokens: ${this.historyManager.summaryTokensUsed}`);
                
                // ãƒ‡ãƒãƒƒã‚°: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æœ€åˆã®éƒ¨åˆ†ã‚’è¡¨ç¤º
                console.log(`ğŸ“Š Summary response preview (first 200 chars): ${summaryText.substring(0, 200)}`);
                
                // JSONãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
                try {
                    const summary: ConversationSummary = JSON.parse(summaryText);
                    return {
                        summary,
                        success: true
                    };
                } catch (parseError) {
                    console.error(`âŒ Failed to parse summary JSON:`, parseError);
                    console.error(`ğŸ“ Full response (first 500 chars):\n${summaryText.substring(0, 500)}`);
                    return {
                        summary: {
                            original_goal_summary: "Summary parsing failed",
                            progress_summary: ["Summary could not be parsed"],
                            current_status: "Unknown status due to parsing error",
                            open_correction_goals: ["Continue with original plan"]
                        },
                        success: false,
                        error: `JSON parsing failed: ${parseError}`
                    };
                }
            } else {
                return {
                    summary: {
                        original_goal_summary: "No summary generated",
                        progress_summary: ["Summary generation failed"],
                        current_status: "Unknown status",
                        open_correction_goals: ["Continue with original plan"]
                    },
                    success: false,
                    error: "No valid response from LLM"
                };
            }
            
        } catch (error) {
            console.error(`âŒ Error generating summary:`, error);
            return {
                summary: {
                    original_goal_summary: "Summary generation error",
                    progress_summary: ["Summary could not be generated due to error"],
                    current_status: "Error occurred during summarization",
                    open_correction_goals: ["Continue with original plan"]
                },
                success: false,
                error: error instanceof Error ? error.message : String(error)
            };
        }
    }

    /**
     * æœ€å¾Œã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®çµæœã‚’æŠ½å‡º
     */
    private extractLastActionResult(): string {
        const lastFewMessages = this.historyManager.messages.slice(-3);
        
        // ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®å¿œç­”ã‚„ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã€diffé©ç”¨çµæœãªã©ã‚’æ¢ã™
        for (const msg of lastFewMessages.reverse()) {
            if (msg.role === 'system' || msg.role === 'assistant') {
                // diffé©ç”¨ã€ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã€ã‚¨ãƒ©ãƒ¼ãªã©ã®çµæœã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç‰¹å®š
                if (msg.content.includes('patch') || 
                    msg.content.includes('diff') || 
                    msg.content.includes('file content') ||
                    msg.content.includes('error') ||
                    msg.content.includes('applied')) {
                    return msg.content.substring(0, 500) + (msg.content.length > 500 ? '...' : '');
                }
            }
        }
        
        return 'Previous action completed successfully.';
    }

    /**
     * çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
     */
    getStats(): any {
        return {
            totalMessages: this.historyManager.messages.length,
            estimatedTokens: this.historyManager.totalTokens,
            summaryThreshold: this.historyManager.summaryThreshold,
            lastSummaryTurn: this.historyManager.lastSummaryTurn,
            timesExceededThreshold: this.historyManager.lastSummaryTurn > 0 ? 1 : 0,
            summaryTokensUsed: this.historyManager.summaryTokensUsed // è¦ç´„ã§æ¶ˆè²»ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°
        };
    }

    /**
     * é–¾å€¤ã‚’å‹•çš„ã«èª¿æ•´
     */
    adjustThreshold(newThreshold: number): void {
        this.historyManager.summaryThreshold = newThreshold;
        console.log(`ğŸ“Š Summary threshold adjusted to: ${newThreshold} tokens`);
    }
}

export default ConversationSummarizer;
