/**
 * å¯¾è©±å±¥æ­´è¦ç´„ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
 * é•·ã„å¯¾è©±å±¥æ­´ã‚’å‹•çš„ã«è¦ç´„ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™ã‚’å›é¿ã™ã‚‹
 */

import type { 
    ConversationSummary, 
    ConversationHistoryManager, 
    SummarizeRequest, 
    SummarizeResponse 
} from './types.js';
import Config from './config.js';
import OpenAIClient from './openAIClient.js';

class ConversationSummarizer {
    private config: Config;
    private openAIClient: OpenAIClient;
    private historyManager: ConversationHistoryManager;
    private correctionGoalsCallback: () => string; // correctionGoalsã‚’å–å¾—ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    // è¨­å®š
    private readonly DEFAULT_SUMMARY_THRESHOLD = 30000; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³é–¾å€¤
    private readonly TOKEN_ESTIMATION_RATIO = 4; // 1ãƒˆãƒ¼ã‚¯ãƒ³ â‰ˆ 4æ–‡å­—ã®è¿‘ä¼¼

    constructor(config: Config, openAIClient: OpenAIClient, correctionGoalsCallback: () => string) {
        this.config = config;
        this.openAIClient = openAIClient;
        this.correctionGoalsCallback = correctionGoalsCallback;
        
        this.historyManager = {
            messages: [],
            totalTokens: 0,
            summaryThreshold: this.config.get('llm.summaryThreshold', this.DEFAULT_SUMMARY_THRESHOLD),
            lastSummaryTurn: 0,
            summaryTokensUsed: 0 // è¦ç´„ã§æ¶ˆè²»ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’åˆæœŸåŒ–
        };
        
        console.log(`ğŸ“ ConversationSummarizer initialized with threshold: ${this.historyManager.summaryThreshold} tokens`);
    }

    /**
     * ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ ã—ã€å¿…è¦ã«å¿œã˜ã¦è¦ç´„ã‚’å®Ÿè¡Œ
     */
    async addMessage(role: string, content: string): Promise<Array<{ role: string, content: string }>> {
        // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        this.historyManager.messages.push({ role, content });
        
        // ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ›´æ–°
        this.updateTokenCount();
        
        console.log(`ğŸ“Š Current conversation: ${this.historyManager.messages.length} messages, ~${this.historyManager.totalTokens} tokens`);
        
        // é–¾å€¤ãƒã‚§ãƒƒã‚¯
        if (this.shouldSummarize()) {
            console.log(`ğŸ”„ Token threshold exceeded, starting dynamic summarization...`);
            return await this.performDynamicSummarization();
        }
        
        return this.historyManager.messages;
    }

    /**
     * ç¾åœ¨ã®å¯¾è©±å±¥æ­´ã‚’å–å¾—
     */
    getCurrentMessages(): Array<{ role: string, content: string }> {
        return this.historyManager.messages;
    }

    /**
     * ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¨å®šå€¤ã‚’æ›´æ–°
     */
    private updateTokenCount(): void {
        const totalText = this.historyManager.messages
            .map(msg => msg.content)
            .join(' ');
        
        // ç°¡æ˜“çš„ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®šï¼ˆå®Ÿéš›ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ã¯å¤šå°‘ç•°ãªã‚‹ï¼‰
        this.historyManager.totalTokens = Math.ceil(totalText.length / this.TOKEN_ESTIMATION_RATIO);
    }

    /**
     * è¦ç´„ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š
     */
    private shouldSummarize(): boolean {
        const exceedsThreshold = this.historyManager.totalTokens > this.historyManager.summaryThreshold;
        const enoughMessagesSinceLastSummary = this.historyManager.messages.length - this.historyManager.lastSummaryTurn >= 5;
        
        return exceedsThreshold && enoughMessagesSinceLastSummary;
    }

    /**
     * å‹•çš„è¦ç´„ã®å®Ÿè¡Œ
     */
    private async performDynamicSummarization(): Promise<Array<{ role: string, content: string }>> {
        try {
            // 1. è¦ç´„ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            const conversationHistory = this.formatConversationForSummary();
            const summarizePrompt = this.config.readPromptSummarizeFile(conversationHistory);
            
            console.log(`ğŸ“ Sending ${summarizePrompt.length} characters to summarization...`);
            
            // 2. åˆ¥ã®LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§è¦ç´„ã‚’ç”Ÿæˆ
            const summaryResponse = await this.generateSummary({
                fullConversationHistory: summarizePrompt,
                model: this.config.get('llm.summaryModel', this.config.get('llm.model', 'gpt-4')),
                temperature: 0.1 // è¦ç´„ã«ã¯ä½ã„æ¸©åº¦ã‚’ä½¿ç”¨
            });
            
            if (!summaryResponse.success) {
                console.error(`âŒ Summarization failed: ${summaryResponse.error}`);
                return this.historyManager.messages; // è¦ç´„å¤±æ•—æ™‚ã¯å…ƒã®å±¥æ­´ã‚’è¿”ã™
            }
            
            // 3. æœ€å¾Œã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®çµæœã‚’ç‰¹å®š
            const lastActionResult = this.extractLastActionResult();
            
            // 4. å¯¾è©±å†é–‹ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            const correctionGoals = this.correctionGoalsCallback();
            const resumePrompt = this.config.readPromptResumeFromSummaryFile(
                JSON.stringify(summaryResponse.summary, null, 2),
                lastActionResult,
                correctionGoals
            );
            
            // 5. æ–°ã—ã„çŸ­ã„å¯¾è©±å±¥æ­´ã«ç½®ãæ›ãˆ
            const systemMessage = this.historyManager.messages.find(msg => msg.role === 'system');
            this.historyManager.messages = [
                ...(systemMessage ? [systemMessage] : []),
                { role: 'user', content: resumePrompt }
            ];
            
            // 6. çµ±è¨ˆã‚’æ›´æ–°
            this.historyManager.lastSummaryTurn = this.historyManager.messages.length;
            this.updateTokenCount();
            
            console.log(`âœ… Dynamic summarization completed:`);
            console.log(`   Original: ${this.historyManager.totalTokens + conversationHistory.length / this.TOKEN_ESTIMATION_RATIO} tokens`);
            console.log(`   Compressed: ${this.historyManager.totalTokens} tokens`);
            console.log(`   Reduction: ${Math.round((1 - this.historyManager.totalTokens / (this.historyManager.totalTokens + conversationHistory.length / this.TOKEN_ESTIMATION_RATIO)) * 100)}%`);
            
            return this.historyManager.messages;
            
        } catch (error) {
            console.error(`âŒ Error during dynamic summarization:`, error);
            return this.historyManager.messages; // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®å±¥æ­´ã‚’ä¿æŒ
        }
    }

    /**
     * è¦ç´„ç”¨ã«å¯¾è©±å±¥æ­´ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
     */
    private formatConversationForSummary(): string {
        return this.historyManager.messages
            .map((msg, index) => `[Turn ${index + 1}] ${msg.role.toUpperCase()}: ${msg.content}`)
            .join('\n\n');
    }

    /**
     * LLMã«è¦ç´„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
     */
    private async generateSummary(request: SummarizeRequest): Promise<SummarizeResponse> {
        try {
            const summarizeMessages = [
                {
                    role: 'system',
                    content: 'You are a specialized AI assistant for summarizing technical conversations about code modifications.'
                },
                {
                    role: 'user',
                    content: request.fullConversationHistory
                }
            ];
            
            const response = await this.openAIClient.fetchOpenAPI(summarizeMessages);
            
            if (response && response.choices && response.choices[0]) {
                const summaryText = response.choices[0].message.content.trim();
                
                // è¦ç´„ã§æ¶ˆè²»ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨˜éŒ²
                const summaryUsage = response.usage || { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 };
                this.historyManager.summaryTokensUsed += summaryUsage.total_tokens;
                
                console.log(`ğŸ“Š Summary API usage - Prompt: ${summaryUsage.prompt_tokens}, Completion: ${summaryUsage.completion_tokens}, Total: ${summaryUsage.total_tokens}`);
                console.log(`ğŸ“Š Cumulative summary tokens: ${this.historyManager.summaryTokensUsed}`);
                
                // ãƒ‡ãƒãƒƒã‚°: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æœ€åˆã®éƒ¨åˆ†ã‚’è¡¨ç¤º
                console.log(`ğŸ“Š Summary response preview (first 200 chars): ${summaryText.substring(0, 200)}`);
                
                // JSONãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
                try {
                    const summary: ConversationSummary = JSON.parse(summaryText);
                    return {
                        summary,
                        success: true
                    };
                } catch (parseError) {
                    console.error(`âŒ Failed to parse summary JSON:`, parseError);
                    console.error(`ğŸ“ Full response (first 500 chars):\n${summaryText.substring(0, 500)}`);
                    return {
                        summary: {
                            original_goal_summary: "Summary parsing failed",
                            progress_summary: ["Summary could not be parsed"],
                            current_status: "Unknown status due to parsing error",
                            open_correction_goals: ["Continue with original plan"]
                        },
                        success: false,
                        error: `JSON parsing failed: ${parseError}`
                    };
                }
            } else {
                return {
                    summary: {
                        original_goal_summary: "No summary generated",
                        progress_summary: ["Summary generation failed"],
                        current_status: "Unknown status",
                        open_correction_goals: ["Continue with original plan"]
                    },
                    success: false,
                    error: "No valid response from LLM"
                };
            }
            
        } catch (error) {
            console.error(`âŒ Error generating summary:`, error);
            return {
                summary: {
                    original_goal_summary: "Summary generation error",
                    progress_summary: ["Summary could not be generated due to error"],
                    current_status: "Error occurred during summarization",
                    open_correction_goals: ["Continue with original plan"]
                },
                success: false,
                error: error instanceof Error ? error.message : String(error)
            };
        }
    }

    /**
     * æœ€å¾Œã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®çµæœã‚’æŠ½å‡º
     */
    private extractLastActionResult(): string {
        const lastFewMessages = this.historyManager.messages.slice(-3);
        
        // ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®å¿œç­”ã‚„ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã€diffé©ç”¨çµæœãªã©ã‚’æ¢ã™
        for (const msg of lastFewMessages.reverse()) {
            if (msg.role === 'system' || msg.role === 'assistant') {
                // diffé©ç”¨ã€ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã€ã‚¨ãƒ©ãƒ¼ãªã©ã®çµæœã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç‰¹å®š
                if (msg.content.includes('patch') || 
                    msg.content.includes('diff') || 
                    msg.content.includes('file content') ||
                    msg.content.includes('error') ||
                    msg.content.includes('applied')) {
                    return msg.content.substring(0, 500) + (msg.content.length > 500 ? '...' : '');
                }
            }
        }
        
        return 'Previous action completed successfully.';
    }

    /**
     * çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
     */
    getStats(): any {
        return {
            totalMessages: this.historyManager.messages.length,
            estimatedTokens: this.historyManager.totalTokens,
            summaryThreshold: this.historyManager.summaryThreshold,
            lastSummaryTurn: this.historyManager.lastSummaryTurn,
            timesExceededThreshold: this.historyManager.lastSummaryTurn > 0 ? 1 : 0,
            summaryTokensUsed: this.historyManager.summaryTokensUsed // è¦ç´„ã§æ¶ˆè²»ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°
        };
    }

    /**
     * é–¾å€¤ã‚’å‹•çš„ã«èª¿æ•´
     */
    adjustThreshold(newThreshold: number): void {
        this.historyManager.summaryThreshold = newThreshold;
        console.log(`ğŸ“Š Summary threshold adjusted to: ${newThreshold} tokens`);
    }
}

export default ConversationSummarizer;
