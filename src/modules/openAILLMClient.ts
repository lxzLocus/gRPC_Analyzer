/**
 * OpenAI LLM Client
 * OpenAI APIã¨ã®é€šä¿¡ã‚’æ‹…å½“
 */

import Config from './config.js';
import { LLMClient, LLMRequest, LLMResponse } from './llmClient.js';

export class OpenAILLMClient implements LLMClient {
    private client: any;
    private initPromise: Promise<void>;
    private config: Config;
    private isInitialized: boolean = false;

    constructor(config: Config, apiKey?: string) {
        this.config = config;
        
        // ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ APIã‚­ãƒ¼ã‚’å–å¾—
        const finalApiKey = apiKey || process.env.OPENAI_API_KEY || '';
        
        console.log(`ğŸ”‘ OpenAILLMClient: Using API key length: ${finalApiKey.length}`);
        console.log(`ğŸ”‘ Available env vars: OPENAI_API_KEY=${!!process.env.OPENAI_API_KEY}`);
        console.log(`ğŸ¤– OpenAILLMClient: Using model: ${this.config.get('openai.model', process.env.OPENAI_MODEL || 'gpt-4.1')}`);
        
        // OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã‚’éåŒæœŸã§è¡Œã†
        this.initPromise = this.initializeClient(finalApiKey);
    }

    private async initializeClient(apiKey: string): Promise<void> {
        try {
            // å‹•çš„importã‚’ä½¿ç”¨ã—ã¦ES moduleså¯¾å¿œ
            const { default: OpenAI } = await import('openai');
            
            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã‚’çµ±ä¸€ï¼šopenai.timeout -> llm.timeout ã®é †ã§å–å¾—
            const timeoutMs = this.config.get('openai.timeout', this.config.get('llm.timeout', 120000));
            console.log(`ğŸ•’ OpenAI client timeout set to: ${timeoutMs}ms`);
            
            this.client = new OpenAI({
                apiKey: apiKey,
                timeout: timeoutMs
            });
            
            this.isInitialized = true;
            console.log('âœ… OpenAI client initialized successfully');
        } catch (error) {
            console.error('âŒ Failed to initialize OpenAI client:', error);
            throw error;
        }
    }

    async waitForInitialization(): Promise<void> {
        return this.initPromise;
    }

    isReady(): boolean {
        return this.isInitialized;
    }

    getProviderName(): string {
        return 'OpenAI';
    }

    async generateContent(request: LLMRequest): Promise<LLMResponse> {
        if (!this.isInitialized) {
            await this.waitForInitialization();
        }

        try {
            const model = request.model || this.config.get('openai.model', process.env.OPENAI_MODEL || 'gpt-4.1');
            const maxTokens = request.maxTokens || this.config.get('llm.maxTokens', 4000);
            
            console.log(`ğŸš€ OpenAI request: model=${model}, maxTokens=${maxTokens}`);

            // APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æº–å‚™
            const apiParams: any = {
                model: model,
                messages: request.messages
            };
            
            // gpt-5ä»¥å¤–ã®å ´åˆã®ã¿max_completion_tokensã‚’è¨­å®š
            if (model !== 'gpt-5' && maxTokens) {
                apiParams.max_completion_tokens = maxTokens;
                console.log(`ğŸ”¢ OpenAI max_completion_tokens: ${maxTokens}`);
            } else if (model === 'gpt-5') {
                console.log(`â„¹ï¸  gpt-5: max_completion_tokensãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™`);
            }

            // gpt-5ä»¥å¤–ã®å ´åˆã®ã¿temperatureã‚’è¨­å®š
            if (model !== 'gpt-5' && request.temperature !== undefined) {
                apiParams.temperature = request.temperature;
                console.log(`ğŸŒ¡ï¸  OpenAI temperature: ${request.temperature}`);
            } else if (model === 'gpt-5') {
                console.log(`â„¹ï¸  gpt-5: temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™`);
            }

            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã®APIå‘¼ã³å‡ºã—
            // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–æ™‚ã¨åŒã˜ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’ä½¿ç”¨
            const apiTimeout = this.config.get('openai.timeout', this.config.get('llm.timeout', 120000));
            console.log(`ğŸ•’ OpenAI API call timeout: ${apiTimeout}ms`);
            
            const apiCall = this.client.chat.completions.create(apiParams);

            const timeoutPromise = new Promise((_, reject) =>
                setTimeout(() => reject(new Error(`OpenAI API timeout after ${apiTimeout}ms`)), apiTimeout)
            );

            const response = await Promise.race([apiCall, timeoutPromise]);

            const content = response.choices[0]?.message?.content || '';
            const usage = response.usage;

            console.log(`âœ… OpenAI response: ${content.length} chars, usage: ${usage?.total_tokens || 0} tokens`);

            return {
                content: content,
                usage: {
                    promptTokens: usage?.prompt_tokens || 0,
                    completionTokens: usage?.completion_tokens || 0,
                    totalTokens: usage?.total_tokens || 0
                }
            };
        } catch (error) {
            console.error('âŒ OpenAI API error:', error);
            throw error;
        }
    }
}

export default OpenAILLMClient;
