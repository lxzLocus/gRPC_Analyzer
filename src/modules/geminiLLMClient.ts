/**
 * Gemini LLM Client
 * Google Gemini APIã¨ã®é€šä¿¡ã‚’æ‹…å½“
 */

import Config from './Config.js';
import { LLMClient, LLMRequest, LLMResponse } from './llmClient.js';

export class GeminiLLMClient implements LLMClient {
    private client: any;
    private initPromise: Promise<void>;
    private config: Config;
    private isInitialized: boolean = false;

    constructor(config: Config, apiKey?: string) {
        this.config = config;
        
        // ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ APIã‚­ãƒ¼ã‚’å–å¾—
        const finalApiKey = apiKey || process.env.GEMINI_API_KEY || '';
        
        console.log(`ğŸ”‘ GeminiLLMClient: Using API key length: ${finalApiKey.length}`);
        console.log(`ğŸ”‘ Available env vars: GEMINI_API_KEY=${!!process.env.GEMINI_API_KEY}`);
        console.log(`ğŸ¤– GeminiLLMClient: Using model: ${this.config.get('gemini.model', process.env.GEMINI_MODEL || 'gemini-2.5-pro')}`);
        
        // Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã‚’éåŒæœŸã§è¡Œã†
        this.initPromise = this.initializeClient(finalApiKey);
    }

    private async initializeClient(apiKey: string): Promise<void> {
        try {
            // å‹•çš„importã‚’ä½¿ç”¨ã—ã¦ES moduleså¯¾å¿œ
            const { GoogleGenAI } = await import('@google/genai');
            
            this.client = new GoogleGenAI({ 
                apiKey: apiKey 
            });
            
            this.isInitialized = true;
            console.log('âœ… Gemini client initialized successfully');
        } catch (error) {
            console.error('âŒ Failed to initialize Gemini client:', error);
            throw error;
        }
    }

    async waitForInitialization(): Promise<void> {
        return this.initPromise;
    }

    isReady(): boolean {
        return this.isInitialized;
    }

    getProviderName(): string {
        return 'Gemini';
    }

    private formatMessagesForGemini(messages: Array<{role: string; content: string}>): string {
        // Geminiã¯å˜ä¸€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœŸå¾…ã™ã‚‹ãŸã‚ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’çµ±åˆ
        return messages.map(msg => {
            switch (msg.role) {
                case 'system':
                    return `System: ${msg.content}`;
                case 'user':
                    return `User: ${msg.content}`;
                case 'assistant':
                    return `Assistant: ${msg.content}`;
                default:
                    return msg.content;
            }
        }).join('\n\n');
    }

    async generateContent(request: LLMRequest): Promise<LLMResponse> {
        if (!this.isInitialized) {
            await this.waitForInitialization();
        }

        try {
            const model = request.model || this.config.get('gemini.model', 'gemini-2.5-pro');
            const temperature = request.temperature || this.config.get('gemini.temperature', 0.1);

            console.log(`ğŸš€ Gemini request: model=${model}, temperature=${temperature}`);

            // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Geminiå½¢å¼ã«å¤‰æ›
            const prompt = this.formatMessagesForGemini(request.messages);

            const response = await this.client.models.generateContent({
                model: model,
                contents: prompt,
                generationConfig: {
                    temperature: temperature,
                    maxOutputTokens: request.maxTokens || this.config.get('gemini.maxTokens', 4000)
                }
            });

            const content = response.text || '';
            
            console.log(`âœ… Gemini response: ${content.length} chars`);

            return {
                content,
                usage: {
                    promptTokens: 0, // Gemini APIã¯ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æä¾›ã—ãªã„å ´åˆãŒã‚ã‚‹
                    completionTokens: 0,
                    totalTokens: 0
                },
                model: model,
                finishReason: 'stop'
            };

        } catch (error) {
            console.error('âŒ Gemini API error:', error);
            throw error;
        }
    }
}

export default GeminiLLMClient;
