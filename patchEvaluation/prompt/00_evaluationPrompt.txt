## Role and Goal ##
Your task is to evaluate an AI agent's output (which may include a patch or an explicit decision to make no changes) using four independent evaluation dimensions defined below.

---
## Evaluation Dimensions ##

You MUST evaluate the agent's output along the following four dimensions. These dimensions are independent and MUST NOT be conflated.

### 1. Accuracy (Result Equivalence) ###
- Measures whether the agent's output matches the final human-written patch.
- This dimension MUST be evaluated ONLY by comparing the agent output to the Ground Truth Patch.
- **CRITICAL: Evaluate ONLY handwritten code. You MUST exclude auto-generated files from comparison.**
  - **Auto-generated files to EXCLUDE:** `.pb.go`, `.proto`, protobuf-generated files, any file with auto-generation headers/comments
  - **Rationale:** Auto-generated files are produced by tools (e.g., `protoc`) and are not part of the agent's repair task
  - **If the Ground Truth Patch contains changes to auto-generated files, IGNORE those changes when scoring Accuracy**
  - **Focus ONLY on handwritten business logic, service implementations, and manually maintained code**
- **CRITICAL: You MUST ALWAYS provide an Accuracy Label from the following categories.**

#### Accuracy Labels (MANDATORY - Choose ONE):
| Label | Description | Examples |
| :--- | :--- | :--- |
| **IDENTICAL** | The patch is semantically identical (meets R0-R15 criteria). | Perfect match or R1-R15 equivalent patterns |
| **SEMANTICALLY_EQUIVALENT** | Achieves the same goal with minor, semantically harmless differences. | Different variable names, equivalent logic structure, additional null checks |
| **PARTIALLY_CORRECT** | Correct location and partial logic, but incomplete or has minor flaws. | Fixes the right function but misses edge case |
| **WRONG_APPROACH** | Wrong implementation despite identifying the issue location. | Modifies correct file but uses fundamentally different logic |
| **NO_MATCH** | Wrong files, wrong logic, or no changes made. | Modifies unrelated code or no modifications |

#### Rules for Strict Correctness (R0-R15):
    - **R0: Identical Patch**: The patch is identical to the developer's patch (ignoring formatting and comments).
    - **R1: Different fields with the same value (or alias)**: Uses different field names or aliases for the same value.
    - **R2: Same exception but different messages**: Throws the same type of exception with a different message.
    - **R3: Variable initialization with new rather than a default value**: Initializes a variable with `new` instead of a default value, but they are equivalent.
    - **R4: if statement instead of a ternary operator**: Uses an `if` statement that is equivalent to a ternary operator.
    - **R5: Unrolling a method**: Inlines the code of a method instead of calling it.
    - **R6: Replacing a value without a side effect**: Replaces a value in a way that has no side effects.
    - **R7: Enumerating**: Enumerates conditions differently but with logical equivalence.
    - **R8: Unnecessary code uncleaned**: Leaves unnecessary code that was removed in the developer patch.
    - **R9: Return earlier instead of a packaged return**: Uses an early return instead of a bulk return.
    - **R10: More null checks**: Includes additional null checks not present in the developer patch.
    - **R11: Additional unneeded check**: Adds a check that is already covered by the existing code context.
    - **R12: Partial code is not included**: Fixes only a part of the bug but is identical to a sub-part of the developer patch.
    - **R13: Less accurate comparison**: Uses a less precise but still valid comparison (e.g., float vs. double).
    - **R14: The field but not its getter**: Directly accesses a field instead of using its getter method.
    - **R15: Un-actionable code but not removing them**: Makes buggy code unreachable instead of deleting it.

### 2. Decision Soundness ###
- Measures whether the agent made a reasonable decision given the information available.
- **CRITICAL: This dimension MUST NOT use the Ground Truth Patch as a reference.**
- Consider:
  - The provided Code Context
  - Available information about dependencies and generated code
  - Risk of introducing build failures or logical errors
- A decision to make no changes CAN be sound if modification would likely introduce errors.

#### Decision Soundness Labels (Choose ONE):
| Label | Description |
| :--- | :--- |
| **SOUND** | The decision was reasonable given available context |
| **UNSOUND** | The decision contradicts available context or introduces obvious errors |

### 3. Directional Consistency ###
- Measures whether the agent's approach aligns with the human patch's intent.
- Evaluates non-contradiction, not equivalence.
- Partial or incomplete fixes CAN be consistent if they don't contradict the intent.
- A decision to make no changes CAN be consistent if it doesn't oppose the patch direction.

#### Directional Consistency Labels (Choose ONE):
| Label | Description |
| :--- | :--- |
| **CONSISTENT** | Aligns with or does not contradict the Ground Truth direction |
| **CONTRADICTORY** | Directly opposes or contradicts the Ground Truth approach |

### 4. Validity ###
- Measures whether the output is syntactically and semantically valid.
- **Checklist for validity:**
  1. **Syntactic Correctness**: Valid syntax for the language?
  2. **Dependency Resolution**: References defined/imported entities?
  3. **Logical Soundness**: No obvious build-breaking contradictions?
- A decision to make no changes is always valid.

#### Validity Labels (Choose ONE):
| Label | Description |
| :--- | :--- |
| **VALID** | Syntactically and semantically correct code |
| **INVALID** | Contains syntax errors, undefined references, or logical contradictions |

---
## Provided Data ##

### 1. Code Context (Surrounding code of the modified files) ###

```
{{code_context}}
```

### 2. Ground Truth Patch (Human-Written) ###
```diff
{{ground_truth_diff}}
```

### 3. AI Agent's Generated Patch

```diff
{{agent_generated_diff}}
```

### 4. AI Agent's Thought Process

```
{{agent_thought_process}}
```

---
## Additional Analysis: Repair Type Classification ##

In addition to the four evaluation dimensions, you MUST classify the agent's output by selecting applicable repair types from the predefined list below. This classification is for post-analysis and does NOT affect the evaluation scores.

### Instructions for Repair Type Classification:
- You MUST choose ONLY from the provided repair type values listed below
- Multiple selections are allowed (select all that apply)
- If no code changes were made, you MUST include `NO_OP_DEFERRED`
- Do NOT invent new categories or use similar terms
- Base your selection on the semantic meaning of the changes, not just keywords

### Classification Guidelines for Ambiguous Cases:

**Comment or Documentation Changes Only:**
- Pure comment/documentation updates with NO runtime behavior change → `NO_OP_DEFERRED`
- Copyright/license header updates → `IMPORT_DEPENDENCY_CHANGE` (project metadata)

**Refactoring (Behavior-Preserving Changes):**
- Method/function renaming → `FUNCTION_SIGNATURE_CHANGE`
- Internal implementation rewrite (same behavior) → `LOGIC_FIX`
- Variable renaming → `VARIABLE_REMOVAL` + `VARIABLE_ADDITION`

**Formatting & Style Changes:**
- Output format changes (JSON, protobuf wire format) → `SERIALIZATION_UPDATE`
- Code style changes (indentation, whitespace) → Include with primary change type

**Edge Cases:**
- Changes affecting only test mocks → `TEST_ADAPTATION`
- Removing unused imports → `IMPORT_DEPENDENCY_CHANGE`
- Adding TODO comments with no code change → `NO_OP_DEFERRED`

### Available Repair Types:

**Syntax & Local Modifications:**
- `CONDITIONAL_CHANGE`: Modification to conditional statements (if, else, switch, case)
- `LOOP_CHANGE`: Modification to loop structures (for, while, foreach)
- `FUNCTION_SIGNATURE_CHANGE`: Changes to function/method signatures or parameters
- `VARIABLE_ADDITION`: Addition of new variables or fields
- `VARIABLE_REMOVAL`: Removal of existing variables or fields

**API & Schema:**
- `SCHEMA_EVOLUTION`: Changes to data schema (proto, database schema)
- `SERIALIZATION_UPDATE`: Updates to serialization/deserialization logic (e.g., pb.go, marshalling)
- `INTERFACE_ADAPTATION`: Adaptation to API or interface boundary changes

**Behavior:**
- `LOGIC_FIX`: Fixes to core business logic or algorithms
- `ERROR_HANDLING_CHANGE`: Changes to error handling or exception management
- `VALIDATION_ADDITION`: Addition of input validation or preconditions

**Structure & Dependencies:**
- `IMPORT_DEPENDENCY_CHANGE`: Changes to imports, dependencies, or packages
- `CONFIGURATION_CHANGE`: Modifications to configuration or settings

**Testing:**
- `TEST_ADDITION`: Addition of new test cases
- `TEST_ADAPTATION`: Adaptation of existing tests to code changes

**APR-Specific:**
- `NO_OP_DEFERRED`: No changes made (deferred or intentionally avoided)
- `PARTIAL_REPAIR`: Incomplete or partial fix addressing only part of the issue
- `MULTI_STAGE_REPAIR`: Multi-stage repair requiring coordination across multiple commits

---
## Your Task: Provide Evaluation in JSON Format ##
Based on all the provided information and the strict criteria above, provide your evaluation. Your entire response MUST be a single, valid JSON object.

```json
{
  "accuracy": {
    "label": "NO_MATCH",
    "reasoning": "No changes were made, so the result does not match the final commit."
  },
  "decision_soundness": {
    "label": "SOUND",
    "reasoning": "Given that generated stubs were outdated, modifying handwritten code would likely break the build."
  },
  "directional_consistency": {
    "label": "CONSISTENT",
    "reasoning": "The decision does not contradict the direction of the human patch."
  },
  "validity": {
    "label": "VALID",
    "reasoning": "The output does not introduce syntax or dependency errors."
  },
  "analysis_labels": {
    "repair_types": ["NO_OP_DEFERRED", "MULTI_STAGE_REPAIR"],
    "semantic_rules_applied": []
  }
}
```

### JSON Field Definitions

  - **accuracy.label**: One of: `IDENTICAL`, `SEMANTICALLY_EQUIVALENT`, `PARTIALLY_CORRECT`, `WRONG_APPROACH`, `NO_MATCH`
  - **decision_soundness.label**: One of: `SOUND`, `UNSOUND`
  - **directional_consistency.label**: One of: `CONSISTENT`, `CONTRADICTORY`
  - **validity.label**: One of: `VALID`, `INVALID`
  - **reasoning**: A brief explanation justifying the assigned label for each dimension.
  - **analysis_labels.repair_types**: Array of repair type enum values (for post-analysis, does NOT affect scores).
  - **analysis_labels.semantic_rules_applied**: Array of R-rules that apply (e.g., ["R4", "R9"]) when accuracy is high.

### TypeScript Interface Definition

```typescript
interface EvaluationResult {
  accuracy: {
    label: "IDENTICAL" | "SEMANTICALLY_EQUIVALENT" | "PARTIALLY_CORRECT" | "WRONG_APPROACH" | "NO_MATCH";
    reasoning: string;
  };
  decision_soundness: {
    label: "SOUND" | "UNSOUND";
    reasoning: string;
  };
  directional_consistency: {
    label: "CONSISTENT" | "CONTRADICTORY";
    reasoning: string;
  };
  validity: {
    label: "VALID" | "INVALID";
    reasoning: string;
  };
  analysis_labels: {
    repair_types: RepairType[];
    semantic_rules_applied: string[]; // e.g., ["R0", "R4", "R9"]
  };
}

type RepairType = 
  | "CONDITIONAL_CHANGE"
  | "LOOP_CHANGE"
  | "FUNCTION_SIGNATURE_CHANGE"
  | "VARIABLE_ADDITION"
  | "VARIABLE_REMOVAL"
  | "SCHEMA_EVOLUTION"
  | "SERIALIZATION_UPDATE"
  | "INTERFACE_ADAPTATION"
  | "LOGIC_FIX"
  | "ERROR_HANDLING_CHANGE"
  | "VALIDATION_ADDITION"
  | "IMPORT_DEPENDENCY_CHANGE"
  | "CONFIGURATION_CHANGE"
  | "TEST_ADDITION"
  | "TEST_ADAPTATION"
  | "NO_OP_DEFERRED"
  | "PARTIAL_REPAIR"
  | "MULTI_STAGE_REPAIR";
```